{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script retrieves and structures annotation data from Hypothes.is, an open-source annotation platform widely utilized in educational contexts, where students collaboratively annotate and comment on digital texts such as articles, academic papers, and online resources. Hypothes.is provides a valuable dataset for analyzing student interactions, highlighting meaningful excerpts, and capturing individual insights directly associated with specific text fragments (Hypothes.is, n.d.). Leveraging students' annotations enhances the construction of personalized knowledge graphs, as these annotations inherently represent authentic user engagement and reflection, making them ideal for building nuanced, context-rich educational applications.\n",
    "\n",
    "Reference:\n",
    "Hypothes.is. (n.d.). Hypothes.is API documentation. Retrieved March 25, 2025, from https://h.readthedocs.io/en/latest/api/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output JSON structure:\n",
    "\n",
    "The script produces a nested JSON object organized by Hypothes.is users and the documents they annotated.\n",
    "Each user key maps to a collection of documents (identified by their URI), and each document contains:\n",
    "- its title,\n",
    "- and a list of annotations made by that user on that document.\n",
    "\n",
    "Each annotation object contains:\n",
    "- `id`: the unique annotation ID from Hypothes.is\n",
    "- `highlighted_text`: the exact text the user selected and annotated\n",
    "- `comment`: the user's written comment (non-empty)\n",
    "- `created`: the timestamp when the annotation was created\n",
    "- `position`: start and end character offsets (if available)\n",
    "- `context`: preceding and following text around the highlight (if available)\n",
    "\n",
    "Annotations are only included if:\n",
    "1. The document has a title.\n",
    "2. The comment is not empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 200 annotations so far...\n",
      "Fetched 400 annotations so far...\n",
      "Fetched 600 annotations so far...\n",
      "Fetched 800 annotations so far...\n",
      "Fetched 1000 annotations so far...\n",
      "Fetched 1200 annotations so far...\n",
      "Fetched 1400 annotations so far...\n",
      "Fetched 1600 annotations so far...\n",
      "Fetched 1800 annotations so far...\n",
      "Fetched 2000 annotations so far...\n",
      "Fetched 2200 annotations so far...\n",
      "Fetched 2400 annotations so far...\n",
      "Fetched 2600 annotations so far...\n",
      "Fetched 2800 annotations so far...\n",
      "Fetched 3000 annotations so far...\n",
      "Fetched 3200 annotations so far...\n",
      "Fetched 3400 annotations so far...\n",
      "Fetched 3600 annotations so far...\n",
      "Fetched 3800 annotations so far...\n",
      "Fetched 4000 annotations so far...\n",
      "Fetched 4200 annotations so far...\n",
      "Fetched 4400 annotations so far...\n",
      "Fetched 4600 annotations so far...\n",
      "Fetched 4800 annotations so far...\n",
      "Fetched 5000 annotations so far...\n",
      "Fetched 5200 annotations so far...\n",
      "Fetched 5400 annotations so far...\n",
      "Fetched 5600 annotations so far...\n",
      "Fetched 5800 annotations so far...\n",
      "Fetched 6000 annotations so far...\n",
      "Fetched 6200 annotations so far...\n",
      "Fetched 6400 annotations so far...\n",
      "Fetched 6600 annotations so far...\n",
      "Fetched 6800 annotations so far...\n",
      "Fetched 7000 annotations so far...\n",
      "Fetched 7200 annotations so far...\n",
      "Fetched 7400 annotations so far...\n",
      "Fetched 7600 annotations so far...\n",
      "Fetched 7800 annotations so far...\n",
      "Fetched 8000 annotations so far...\n",
      "Fetched 8200 annotations so far...\n",
      "Fetched 8400 annotations so far...\n",
      "Fetched 8600 annotations so far...\n",
      "Fetched 8800 annotations so far...\n",
      "Fetched 9000 annotations so far...\n",
      "Fetched 9200 annotations so far...\n",
      "Fetched 9400 annotations so far...\n",
      "Fetched 9600 annotations so far...\n",
      "Fetched 9800 annotations so far...\n",
      "Fetched 10000 annotations so far...\n",
      "\n",
      "Successfully fetched 10000 annotations.\n",
      "Annotations successfully organized and saved to annotations_database.json.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "HYPOTHESIS_API_URL = \"https://api.hypothes.is/api/search\"\n",
    "\n",
    "def fetch_annotations_paginated(total_annotations, per_page=200, sleep_between_calls=1):\n",
    "    annotations = []\n",
    "    offset = 0\n",
    "\n",
    "    while len(annotations) < total_annotations:\n",
    "        params = {\n",
    "            \"limit\": per_page,\n",
    "            \"offset\": offset,\n",
    "        }\n",
    "\n",
    "        response = requests.get(HYPOTHESIS_API_URL, params=params)\n",
    "        response.raise_for_status()\n",
    "        batch = response.json().get('rows', [])\n",
    "\n",
    "        if not batch:\n",
    "            break\n",
    "\n",
    "        annotations.extend(batch)\n",
    "        offset += per_page\n",
    "\n",
    "        print(f\"Fetched {len(annotations)} annotations so far...\")\n",
    "\n",
    "        time.sleep(sleep_between_calls)\n",
    "\n",
    "    return annotations[:total_annotations]\n",
    "\n",
    "# Organize annotations with all required filters applied\n",
    "def organize_annotations(annotations):\n",
    "    data = defaultdict(lambda: defaultdict(lambda: {\"title\": \"\", \"annotations\": []}))\n",
    "\n",
    "    for ann in annotations:\n",
    "        doc_title = ann.get('document', {}).get('title', [])\n",
    "        comment = ann.get('text', '').strip()\n",
    "\n",
    "        # Skip annotations without document titles or empty comments\n",
    "        if not doc_title or not doc_title[0].strip() or not comment:\n",
    "            continue\n",
    "\n",
    "        doc_title = doc_title[0].strip()\n",
    "        user = ann.get('user', 'unknown_user').split(':')[1].split('@')[0]\n",
    "        doc_uri = ann.get('uri', 'unknown_document')\n",
    "\n",
    "        annotation = {\n",
    "            \"id\": ann.get('id'),\n",
    "            \"highlighted_text\": \"\",\n",
    "            \"comment\": comment,\n",
    "            \"created\": ann.get('created'),\n",
    "            \"position\": {},\n",
    "            \"context\": {}\n",
    "        }\n",
    "\n",
    "        target = ann.get('target', [])\n",
    "        if target:\n",
    "            selectors = target[0].get('selector', [])\n",
    "            for selector in selectors:\n",
    "                if selector['type'] == 'TextQuoteSelector':\n",
    "                    annotation[\"highlighted_text\"] = selector.get('exact', '')\n",
    "                    annotation[\"context\"] = {\n",
    "                        \"preceding_text\": selector.get('prefix', ''),\n",
    "                        \"following_text\": selector.get('suffix', '')\n",
    "                    }\n",
    "                elif selector['type'] == 'TextPositionSelector':\n",
    "                    annotation[\"position\"] = {\n",
    "                        \"start_char\": selector.get('start'),\n",
    "                        \"end_char\": selector.get('end')\n",
    "                    }\n",
    "\n",
    "        doc_entry = data[user][doc_uri]\n",
    "        doc_entry[\"title\"] = doc_title\n",
    "        doc_entry[\"annotations\"].append(annotation)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    TOTAL_ANNOTATIONS = 10000\n",
    "    annotations = fetch_annotations_paginated(total_annotations=TOTAL_ANNOTATIONS)\n",
    "\n",
    "    print(f\"\\nSuccessfully fetched {len(annotations)} annotations.\")\n",
    "\n",
    "    structured_data = organize_annotations(annotations)\n",
    "\n",
    "    # Save structured data to JSON\n",
    "    with open(\"annotations_database.json\", \"w\", encoding='utf-8') as f:\n",
    "        json.dump(structured_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"Annotations successfully organized and saved to annotations_database.json.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
