{
    "metadata": {
        "filename": "Multimodal_Interfaces_A_Survey_of_Principles_Model-1 (1).pdf",
        "total_pages": 25,
        "processing_timestamp": "2025-04-09T12:52:39.236166"
    },
    "pages": [
        {
            "page_number": 1,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "Multimodal Interfaces: A Survey of Principles, Models",
                    "bbox": {
                        "x0": 140.16900634765625,
                        "y0": 150.8599853515625,
                        "x1": 466.92706298828125,
                        "y1": 164.7799835205078
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and Frameworks",
                    "bbox": {
                        "x0": 246.8289031982422,
                        "y0": 168.3800048828125,
                        "x1": 349.0295715332031,
                        "y1": 182.3000030517578
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Bruno Dumas1, Denis Lalanne1, Sharon Oviatt2",
                    "bbox": {
                        "x0": 209.29640197753906,
                        "y0": 205.52001953125,
                        "x1": 397.98388671875,
                        "y1": 216.5599822998047
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "1 DIVA Group, University of Fribourg",
                    "bbox": {
                        "x0": 234.2664031982422,
                        "y0": 228.86000061035156,
                        "x1": 372.98907470703125,
                        "y1": 238.16000366210938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Bd de Pérolles 90, 1700 Fribourg, Switzerland",
                    "bbox": {
                        "x0": 214.22509765625,
                        "y0": 239.60000610351562,
                        "x1": 381.6895751953125,
                        "y1": 248.48001098632812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "{bruno.dumas, denis.lalanne}@unifr.ch",
                    "bbox": {
                        "x0": 231.8159942626953,
                        "y0": 250.16000366210938,
                        "x1": 375.42333984375,
                        "y1": 259.0400085449219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "2 Incaa Designs",
                    "bbox": {
                        "x0": 275.7749938964844,
                        "y0": 270.3800354003906,
                        "x1": 331.4708251953125,
                        "y1": 279.6800231933594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "821 Second Ave., Ste. 1100, Seattle WA. 98104",
                    "bbox": {
                        "x0": 211.22149658203125,
                        "y0": 281.1200256347656,
                        "x1": 384.6591491699219,
                        "y1": 290.0000305175781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "oviatt@incaadesigns.org",
                    "bbox": {
                        "x0": 259.13238525390625,
                        "y0": 291.6800231933594,
                        "x1": 348.1188659667969,
                        "y1": 300.5600280761719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Abstract. The grand challenge of multimodal interface creation is to build",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 332.0,
                        "x1": 442.6248779296875,
                        "y1": 340.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "reliable processing systems able to analyze and understand multiple",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 342.32000732421875,
                        "x1": 442.5850830078125,
                        "y1": 351.20001220703125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "communication means in real-time. This opens a number of associated issues",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 352.8800048828125,
                        "x1": 442.5012512207031,
                        "y1": 361.760009765625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "covered by this chapter, such as heterogeneous data types fusion, architectures",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 363.1999816894531,
                        "x1": 442.56732177734375,
                        "y1": 372.0799865722656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "for real-time processing, dialog management, machine learning for multimodal",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 373.5199890136719,
                        "x1": 442.60198974609375,
                        "y1": 382.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interaction, modeling languages, frameworks, etc. This chapter does not intend",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 384.0799865722656,
                        "x1": 442.4981689453125,
                        "y1": 392.9599914550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "to cover exhaustively all the issues related to multimodal interfaces creation and",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 394.3999938964844,
                        "x1": 442.56744384765625,
                        "y1": 403.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "some hot topics, such as error handling, have been left aside. The chapter starts",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 404.7200012207031,
                        "x1": 442.5850524902344,
                        "y1": 413.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "with the features and advantages associated with multimodal interaction, with a",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 415.2799987792969,
                        "x1": 442.6117248535156,
                        "y1": 424.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "focus on particular findings and guidelines, as well as cognitive foundations",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 425.6000061035156,
                        "x1": 442.5762634277344,
                        "y1": 434.4800109863281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "underlying multimodal interaction. The chapter then focuses on the driving",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 435.91998291015625,
                        "x1": 442.64727783203125,
                        "y1": 444.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "theoretical principles, time-sensitive software architectures and multimodal",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 446.239990234375,
                        "x1": 442.5823059082031,
                        "y1": 455.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "fusion and fission issues. Modeling of multimodal interaction as well as tools",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 456.79998779296875,
                        "x1": 442.5978698730469,
                        "y1": 465.67999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "allowing rapid creation of multimodal interfaces are then presented. The article",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 467.1199951171875,
                        "x1": 442.5850830078125,
                        "y1": 476.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "concludes with an outline of the current state of multimodal interaction research",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 477.44000244140625,
                        "x1": 442.66510009765625,
                        "y1": 486.32000732421875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "in Switzerland, and also summarizes the major future challenges in the field.",
                    "bbox": {
                        "x0": 153.39019775390625,
                        "y0": 488.0,
                        "x1": 429.08148193359375,
                        "y1": 496.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "1 Introduction",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 530.5400390625,
                        "x1": 205.38009643554688,
                        "y1": 542.5400390625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Of the numerous ways explored by researchers to enhance human-computer",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 558.3200073242188,
                        "x1": 470.82354736328125,
                        "y1": 568.1600341796875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "communication, multimodal interaction has shown much development in the past",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 569.8399658203125,
                        "x1": 470.709228515625,
                        "y1": 579.6799926757812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "decade. On one hand, multimodal interfaces target a more “human” way of interacting",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 581.5999755859375,
                        "x1": 470.78436279296875,
                        "y1": 591.4400024414062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "with computers, by means of speech, gestures or other modalities, as well as being",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 593.1199951171875,
                        "x1": 470.7753601074219,
                        "y1": 602.9600219726562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "preferred over unimodal interfaces by users [49]; on the other hand, multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 604.6400146484375,
                        "x1": 470.80010986328125,
                        "y1": 614.4800415039062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interfaces have been demonstrated to offer better flexibility and reliability than other",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 616.1599731445312,
                        "x1": 470.7482604980469,
                        "y1": 626.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "human/machine interaction means [51].",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 627.6799926757812,
                        "x1": 283.7899169921875,
                        "y1": 637.52001953125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "As a research subject, multimodal interaction encompasses a broad spectrum of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 639.2000122070312,
                        "x1": 470.72894287109375,
                        "y1": 649.0400390625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "research domains, from cognitive psychology to software engineering, including",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 650.719970703125,
                        "x1": 470.7740783691406,
                        "y1": 660.5599975585938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "human-computer interaction, which is already cross-disciplinary. While cognitive",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 662.239990234375,
                        "x1": 470.77813720703125,
                        "y1": 672.0800170898438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "psychologists study how the human brain processes information and interacts through",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 674.0,
                        "x1": 470.6304931640625,
                        "y1": 683.8400268554688
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 153.11300659179688,
                        "y0": 342.0419921875,
                        "x1": 263.4339904785156,
                        "y1": 351.4779968261719
                    },
                    "text_content": "reliable processing systems",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 287.1159973144531,
                        "y0": 331.72198486328125,
                        "x1": 364.9800109863281,
                        "y1": 341.1579895019531
                    },
                    "text_content": "multimodal interface",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 308.6369934082031,
                        "y0": 342.0419921875,
                        "x1": 336.6319885253906,
                        "y1": 351.4779968261719
                    },
                    "text_content": "analyze",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 364.93701171875,
                        "y0": 342.0419921875,
                        "x1": 404.93701171875,
                        "y1": 351.4779968261719
                    },
                    "text_content": "understand",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 153.11300659179688,
                        "y0": 342.0419921875,
                        "x1": 442.8630065917969,
                        "y1": 362.0379943847656
                    },
                    "text_content": "reliable processing systems able to analyze and understand multiple \ncommunication means in real-time. This opens a number of associated issues",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 273.8900146484375,
                        "y0": 362.9219970703125,
                        "x1": 391.6610107421875,
                        "y1": 372.35699462890625
                    },
                    "text_content": "heterogeneous data types fusion,",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 396.33599853515625,
                        "y0": 362.9219970703125,
                        "x1": 442.8450012207031,
                        "y1": 372.35699462890625
                    },
                    "text_content": "architectures",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 166.45899963378906,
                        "y0": 373.24200439453125,
                        "x1": 199.45199584960938,
                        "y1": 382.677001953125
                    },
                    "text_content": "real-time",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 245.38400268554688,
                        "y0": 373.24200439453125,
                        "x1": 317.2460021972656,
                        "y1": 382.677001953125
                    },
                    "text_content": "dialog management,",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 321.8139953613281,
                        "y0": 373.24200439453125,
                        "x1": 385.1510009765625,
                        "y1": 382.677001953125
                    },
                    "text_content": "machine learning",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 153.11300659179688,
                        "y0": 373.24200439453125,
                        "x1": 442.8800048828125,
                        "y1": 393.23699951171875
                    },
                    "text_content": "for real-time processing, dialog management, machine learning for multimodal \ninteraction, modeling languages, frameworks, etc.  This chapter does not intend",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 196.3939971923828,
                        "y0": 383.802001953125,
                        "x1": 269.4360046386719,
                        "y1": 393.23699951171875
                    },
                    "text_content": "modeling languages,",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 220.6540069580078,
                        "y0": 477.1619873046875,
                        "x1": 410.6099853515625,
                        "y1": 486.5979919433594
                    },
                    "text_content": "outline of the current state of multimodal interaction",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 213.7259979248047,
                        "y0": 581.2919921875,
                        "x1": 301.7489929199219,
                        "y1": 591.7470092773438
                    },
                    "text_content": "multimodal interfaces",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 336.052001953125,
                        "y0": 581.2919921875,
                        "x1": 414.94500732421875,
                        "y1": 591.7470092773438
                    },
                    "text_content": "more “human” way",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 204.01300048828125,
                        "y0": 592.81201171875,
                        "x1": 393.72100830078125,
                        "y1": 603.2680053710938
                    },
                    "text_content": "y means of speech, gestures or other modalities",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 604.33203125,
                        "x1": 311.36199951171875,
                        "y1": 614.7869873046875
                    },
                    "text_content": "preferred over unimodal interfaces by users",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 327.36700439453125,
                        "y0": 615.8519897460938,
                        "x1": 367.3219909667969,
                        "y1": 626.3070068359375
                    },
                    "text_content": "flexibility",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 387.5580139160156,
                        "y0": 615.8519897460938,
                        "x1": 426.9419860839844,
                        "y1": 626.3070068359375
                    },
                    "text_content": "reliability",
                    "comment_info": null
                }
            ],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 2,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "2 Bruno Dumas1, Denis Lalanne1, Sharon Oviatt2",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 121.99996948242188,
                        "x1": 329.2164001464844,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "various modalities, interaction practitioners are interested by how humans use",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.1199951171875,
                        "x1": 470.8024597167969,
                        "y1": 158.9600067138672
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal interfaces, and finally software engineers are interested in building tools",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 160.6400146484375,
                        "x1": 470.6894226074219,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and systems supporting the development of such multimodal interfaces, thus studying",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 172.15997314453125,
                        "x1": 470.6600341796875,
                        "y1": 181.99998474121094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "software architectures and multimodal processing techniques.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 183.91998291015625,
                        "x1": 371.4729919433594,
                        "y1": 193.75999450683594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Cognitive psychologists have extensively studied how humans perceive, process,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 195.44000244140625,
                        "x1": 470.7624206542969,
                        "y1": 205.28001403808594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and express multimodal information; their conclusions are of interest for developers",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 206.96002197265625,
                        "x1": 470.6796875,
                        "y1": 216.80003356933594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and HCI practitioners. The creation of a typical multimodal application requires a",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 218.47998046875,
                        "x1": 470.6501770019531,
                        "y1": 228.3199920654297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "number of different components and careful implementation work. Hence, “good",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 230.0,
                        "x1": 470.7536926269531,
                        "y1": 239.8400115966797
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "practices” and algorithms regarding the general architecture of a multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 241.52001953125,
                        "x1": 470.67974853515625,
                        "y1": 251.3600311279297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "application, its fusion and fission engines or dialogue management components",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 253.03997802734375,
                        "x1": 470.7191162109375,
                        "y1": 262.8799743652344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "emerged during the past 20 years [13, 62]. In a more theoretical way, modeling of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 264.55999755859375,
                        "x1": 470.76904296875,
                        "y1": 274.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal interaction and, generally speaking, of the underlying human-machine",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 276.08001708984375,
                        "x1": 470.80865478515625,
                        "y1": 285.9200134277344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "dialog has seen extensive work. This theoretical work leads to the definition of a",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 287.8399658203125,
                        "x1": 470.640380859375,
                        "y1": 297.6799621582031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "number of languages dedicated to multimodal data description, multimodal human-",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 299.3599853515625,
                        "x1": 470.8221435546875,
                        "y1": 309.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "machine dialog modeling or multimodal applications scripting. Together with these",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 310.8800048828125,
                        "x1": 470.6698913574219,
                        "y1": 320.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "different languages, different tools targeted at expediting the creation of multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 322.4000244140625,
                        "x1": 470.68951416015625,
                        "y1": 332.2400207519531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interfaces have appeared.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 333.91998291015625,
                        "x1": 226.30780029296875,
                        "y1": 343.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "This chapter runs the spectrum from cognitive foundations to development tools,",
                    "bbox": {
                        "x0": 139.24009704589844,
                        "y0": 345.44000244140625,
                        "x1": 470.6707458496094,
                        "y1": 355.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "with a particular emphasis on the multimodal processing aspects. The article is not an",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 356.9599914550781,
                        "x1": 470.6305236816406,
                        "y1": 366.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "exhaustive summary of the findings and issues in this broad and multidisciplinary",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 368.47998046875,
                        "x1": 470.787109375,
                        "y1": 378.3199768066406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "field, but rather presents the major issues and findings, with an emphasis on the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 380.0,
                        "x1": 470.6994323730469,
                        "y1": 389.8399963378906
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "driving principles for the creation of multimodal interfaces, their models, and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 391.760009765625,
                        "x1": 470.67974853515625,
                        "y1": 401.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "programming frameworks. The chapter begins with a global view on multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 403.2799987792969,
                        "x1": 470.7387390136719,
                        "y1": 413.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interaction, with a presentation of its aims and advantages, its features, and cognitive",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 414.79998779296875,
                        "x1": 470.71356201171875,
                        "y1": 424.6399841308594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "foundations underlying multimodal systems; seminal works, findings and guidelines",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 426.32000732421875,
                        "x1": 470.6305236816406,
                        "y1": 436.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "particular to multimodal interaction conclude this second section. The third section",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 437.8399963378906,
                        "x1": 470.62066650390625,
                        "y1": 447.67999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "gives a detailed look at theoretical and practical principles of multimodal systems,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 449.3599853515625,
                        "x1": 470.7377624511719,
                        "y1": 459.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "architectures and key components of such systems; among those key components,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 460.8800048828125,
                        "x1": 470.74859619140625,
                        "y1": 470.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "fusion engines, fission engines and dialog management all have a dedicated",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 472.3999938964844,
                        "x1": 470.65020751953125,
                        "y1": 482.239990234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "subsection. The third section ends with a view of potential uses of machine learning",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 484.1600036621094,
                        "x1": 470.7115173339844,
                        "y1": 494.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "for multimodal interaction. The fourth section focuses on modeling and creation of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 495.67999267578125,
                        "x1": 470.7191162109375,
                        "y1": 505.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal interfaces, with subsections detailing models, modeling languages and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 507.199951171875,
                        "x1": 470.6404113769531,
                        "y1": 517.0399780273438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "programming frameworks for multimodal interaction. The fifth section is devoted to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 518.719970703125,
                        "x1": 470.75640869140625,
                        "y1": 528.5599975585938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal applications in Switzerland, and the sixth and last section concludes this",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 530.239990234375,
                        "x1": 470.63043212890625,
                        "y1": 540.0800170898438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "chapter with future directions.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 541.760009765625,
                        "x1": 245.46205139160156,
                        "y1": 551.6000366210938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "2 Foundations, Aims and Features of Multimodal Interaction",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 579.260009765625,
                        "x1": 443.72930908203125,
                        "y1": 591.260009765625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "This section will present the aims underlying multimodal interaction research, as well",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 607.280029296875,
                        "x1": 470.71173095703125,
                        "y1": 617.1200561523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "as the distinctive features of multimodal interfaces compared to other types of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 618.7999877929688,
                        "x1": 470.6797180175781,
                        "y1": 628.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interfaces. The first part will present a general view of multimodal systems, and more",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 630.3200073242188,
                        "x1": 470.6888427734375,
                        "y1": 640.1600341796875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "specifically their aims and advantages. The section continues with a part focused on",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 641.8399658203125,
                        "x1": 470.7535095214844,
                        "y1": 651.6799926757812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "particular features of multimodal interfaces, compared to standard GUI interfaces.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 653.3599853515625,
                        "x1": 470.6993408203125,
                        "y1": 663.2000122070312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The third part introduces cognitive theories linked to multimodal interaction design.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 664.8800048828125,
                        "x1": 470.7190246582031,
                        "y1": 674.7200317382812
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 195.13299560546875,
                        "x1": 471.07000732421875,
                        "y1": 217.10797119140625
                    },
                    "text_content": "Cognitive psychologists have extensively studied how humans perceive, process, \nand express multimodal information; their conclusions are of interest for developers",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 415.1210021972656,
                        "y0": 287.531982421875,
                        "x1": 453.92498779296875,
                        "y1": 297.98699951171875
                    },
                    "text_content": "definition o",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 299.052001953125,
                        "x1": 384.17999267578125,
                        "y1": 309.50701904296875
                    },
                    "text_content": "number of languages dedicated to multimodal data description,",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 291.4419860839844,
                        "y0": 345.13299560546875,
                        "x1": 470.9779968261719,
                        "y1": 355.5880126953125
                    },
                    "text_content": "cognitive foundations to development tools,",
                    "comment_info": null
                }
            ],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 3,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "Multimodal Interfaces: A Survey of Principles, Models and Frameworks 3",
                    "bbox": {
                        "x0": 185.16659545898438,
                        "y0": 121.99996948242188,
                        "x1": 470.8302001953125,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Finally, the fourth part presents seminal works, findings and guidelines in the field of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.1199951171875,
                        "x1": 470.70526123046875,
                        "y1": 158.9600067138672
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal interaction.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 160.6400146484375,
                        "x1": 218.8153076171875,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "2.1 Aims and Advantages of Multimodal Systems",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 194.0,
                        "x1": 339.04913330078125,
                        "y1": 203.8400115966797
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Multimodal systems are computer systems endowed with multimodal capabilities for",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 216.79998779296875,
                        "x1": 470.7091064453125,
                        "y1": 226.63999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "human/machine interaction and able to interpret information from various sensory and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 228.32000732421875,
                        "x1": 470.7589416503906,
                        "y1": 238.16001892089844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "communication channels. Literally, multimodal interaction offers a set of “modalities”",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 239.8399658203125,
                        "x1": 470.6304016113281,
                        "y1": 249.6799774169922
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "to users to allow them to interact with the machine. According to Oviatt [49],",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 251.3599853515625,
                        "x1": 470.84600830078125,
                        "y1": 261.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "« Multimodal interfaces process two or more combined user input modes (such as",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 262.8800048828125,
                        "x1": 470.76971435546875,
                        "y1": 272.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "speech, pen, touch, manual gesture, gaze, and head and body movements) in a",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 274.6400146484375,
                        "x1": 470.7584533691406,
                        "y1": 284.4800109863281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "coordinated manner with multimedia system output. They are a new class of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 286.15997314453125,
                        "x1": 470.7684020996094,
                        "y1": 295.9999694824219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interfaces that aim to recognize naturally occurring forms of human language and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 297.67999267578125,
                        "x1": 470.7484436035156,
                        "y1": 307.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "behavior, and which incorporate one or more recognition-based technologies (e.g.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 309.20001220703125,
                        "x1": 470.8128967285156,
                        "y1": 319.0400085449219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "speech, pen, vision) ». Two unique features of multimodal architectures and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 320.719970703125,
                        "x1": 470.7838439941406,
                        "y1": 330.5599670410156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "processing are: (1) the fusion of different types of data; and (2) real-time processing",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 332.239990234375,
                        "x1": 470.7764587402344,
                        "y1": 342.0799865722656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and temporal constraints imposed on information processing [46, 54].",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 343.760009765625,
                        "x1": 403.8324279785156,
                        "y1": 353.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Thus, multimodal systems represent a new class of user-machine interfaces, different",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 355.2799987792969,
                        "x1": 470.81231689453125,
                        "y1": 365.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "from standard WIMP interfaces. They tend to emphasize the use of richer and more",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 367.0400085449219,
                        "x1": 470.8206481933594,
                        "y1": 376.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "natural ways of communication, such as speech or gestures, and more generally all the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 378.55999755859375,
                        "x1": 470.7215576171875,
                        "y1": 388.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "five senses. Hence, the objective of multimodal interfaces is twofold: (1) to support",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 390.0799865722656,
                        "x1": 470.7401428222656,
                        "y1": 399.91998291015625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and accommodate users’ perceptual and communicative capabilities; and (2) to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 401.6000061035156,
                        "x1": 470.7934265136719,
                        "y1": 411.44000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "integrate computational skills of computers in the real world, by offering more natural",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 413.1199951171875,
                        "x1": 470.79730224609375,
                        "y1": 422.9599914550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "ways of interaction to humans.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 424.6399841308594,
                        "x1": 247.98109436035156,
                        "y1": 434.47998046875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Multimodal interfaces were first seen as more efficient than unimodal interfaces;",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 436.1600036621094,
                        "x1": 470.7531433105469,
                        "y1": 446.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "however, evaluations showed that multimodal interfaces only speed up task",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 447.67999267578125,
                        "x1": 470.79931640625,
                        "y1": 457.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "completion by 10% [50]. Hence, efficiency should not be considered the main",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 459.1999816894531,
                        "x1": 470.7557678222656,
                        "y1": 469.03997802734375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "advantage of multimodal interfaces. On the other hand, multimodal interfaces have",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 470.9599914550781,
                        "x1": 470.7288513183594,
                        "y1": 480.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "been shown to improve error handling & reliability: users made 36% fewer errors",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 482.47998046875,
                        "x1": 470.8160400390625,
                        "y1": 492.3199768066406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "with a multimodal interface than with a unimodal interface [50]. Multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 494.0,
                        "x1": 470.8249206542969,
                        "y1": 503.8399963378906
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interfaces also add greater expressive power, and greater potential precision in visual-",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 505.52001953125,
                        "x1": 470.8221435546875,
                        "y1": 515.3600463867188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "spatial tasks. Finally, they provide improved support for users’ preferred interaction",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 517.0400390625,
                        "x1": 470.7819519042969,
                        "y1": 526.8800659179688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "style, since 95%-100% of users prefer multimodal interaction over unimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 528.5599975585938,
                        "x1": 470.784912109375,
                        "y1": 538.4000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interaction [50].",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 540.0799560546875,
                        "x1": 189.41981506347656,
                        "y1": 549.9199829101562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "2.2 Features",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 573.4400024414062,
                        "x1": 182.17434692382812,
                        "y1": 583.280029296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Compared to other types of human/computer interaction, multimodal interaction seeks",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 596.239990234375,
                        "x1": 470.81036376953125,
                        "y1": 606.0800170898438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "to offer users a more natural and transparent interaction, using speech, gestures, gaze",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 607.760009765625,
                        "x1": 470.6699523925781,
                        "y1": 617.6000366210938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "direction, etc. Multimodal interfaces are hence expected to offer easier, more",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 619.280029296875,
                        "x1": 470.814453125,
                        "y1": 629.1200561523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "expressively powerful and more intuitive ways to use computers. Multimodal systems",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 630.7999877929688,
                        "x1": 470.8127746582031,
                        "y1": 640.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "have the potential to enhance human/computer interaction in a number of ways:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 642.3200073242188,
                        "x1": 443.8953552246094,
                        "y1": 652.1600341796875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Enhanced robustness due to combining different partial information sources;",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 654.0800170898438,
                        "x1": 442.84100341796875,
                        "y1": 664.4021606445312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Flexible personalization based on user and context;",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 665.5999755859375,
                        "x1": 341.2888488769531,
                        "y1": 675.922119140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• New functionality involving multi-user and mobile interaction.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 677.1199951171875,
                        "x1": 388.22021484375,
                        "y1": 687.442138671875
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 268.8190002441406,
                        "y0": 239.531982421875,
                        "x1": 360.6809997558594,
                        "y1": 249.98699951171875
                    },
                    "text_content": "multimodal interaction",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 395.42999267578125,
                        "y0": 239.531982421875,
                        "x1": 470.93798828125,
                        "y1": 249.98699951171875
                    },
                    "text_content": "set of “modalities”",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 242.78199768066406,
                        "y0": 251.052001953125,
                        "x1": 355.6319885253906,
                        "y1": 261.50701904296875
                    },
                    "text_content": "interact with the machine.",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 176.78599548339844,
                        "y0": 251.052001953125,
                        "x1": 199.49200439453125,
                        "y1": 261.50701904296875
                    },
                    "text_content": "allow",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 274.3330078125,
                        "x1": 444.59698486328125,
                        "y1": 284.7869873046875
                    },
                    "text_content": "speech, pen, touch, manual gesture, gaze, and head and body movements)",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 285.85198974609375,
                        "x1": 210.35499572753906,
                        "y1": 296.3070068359375
                    },
                    "text_content": "coordinated manner",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 239.45700073242188,
                        "y0": 285.85198974609375,
                        "x1": 349.6409912109375,
                        "y1": 296.3070068359375
                    },
                    "text_content": "multimedia system output.",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 255.718994140625,
                        "y0": 320.4119873046875,
                        "x1": 337.88800048828125,
                        "y1": 330.86700439453125
                    },
                    "text_content": "unique features of",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 219.46400451660156,
                        "y0": 331.9320068359375,
                        "x1": 353.07598876953125,
                        "y1": 342.38800048828125
                    },
                    "text_content": "fusion of different types of data;",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 388.4309997558594,
                        "y0": 331.9320068359375,
                        "x1": 471.0840148925781,
                        "y1": 342.38800048828125
                    },
                    "text_content": "real-time processing",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 141.66700744628906,
                        "y0": 343.4530029296875,
                        "x1": 223.54800415039062,
                        "y1": 353.9079895019531
                    },
                    "text_content": "temporal constraints",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 376.6669921875,
                        "y0": 389.7720031738281,
                        "x1": 411.12200927734375,
                        "y1": 400.22698974609375
                    },
                    "text_content": "twofold:",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 389.7720031738281,
                        "x1": 471.0469970703125,
                        "y1": 411.74700927734375
                    },
                    "text_content": "five senses. Hence, the objective of multimodal interfaces is twofold: (1) to support \nand accommodate users’ perceptual and communicative capabilities; and (2) to",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 412.81298828125,
                        "x1": 370.2250061035156,
                        "y1": 423.26800537109375
                    },
                    "text_content": "integrate computational skills of computers in the real world,",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 442.7799987792969,
                        "y0": 412.81298828125,
                        "x1": 471.10400390625,
                        "y1": 423.26800537109375
                    },
                    "text_content": "natural",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 158.61199951171875,
                        "y0": 424.3320007324219,
                        "x1": 201.88299560546875,
                        "y1": 434.7869873046875
                    },
                    "text_content": "interaction",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 447.37200927734375,
                        "x1": 471.10699462890625,
                        "y1": 469.34698486328125
                    },
                    "text_content": "however, evaluations showed that multimodal interfaces only speed up task \ncompletion by 10% [50]. Hence, efficiency should not be considered the main",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 189.7949981689453,
                        "y0": 482.1719970703125,
                        "x1": 471.12298583984375,
                        "y1": 492.62799072265625
                    },
                    "text_content": "improve error handling & reliability: users made 36% fewer errors",
                    "comment_info": null
                }
            ],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 4,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "4 Bruno Dumas1, Denis Lalanne1, Sharon Oviatt2",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 121.99996948242188,
                        "x1": 329.2164001464844,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "When comparing multimodal user interfaces (MUI) with standard graphical user",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 160.6400146484375,
                        "x1": 470.7289733886719,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interfaces (GUI), it is possible to draw the following differences [54]:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 172.15997314453125,
                        "x1": 403.5478515625,
                        "y1": 181.99998474121094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Table 1. Differences between GUIs and MUIs.",
                    "bbox": {
                        "x0": 204.92799377441406,
                        "y0": 195.44000244140625,
                        "x1": 390.9157409667969,
                        "y1": 205.28001403808594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "GUI MUI",
                    "bbox": {
                        "x0": 197.0991973876953,
                        "y0": 210.32000732421875,
                        "x1": 383.25567626953125,
                        "y1": 220.16001892089844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Single input stream Multiple input streams",
                    "bbox": {
                        "x0": 167.66070556640625,
                        "y0": 227.3599853515625,
                        "x1": 418.21075439453125,
                        "y1": 237.1999969482422
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Atomic, deterministic Continuous, probabilistic",
                    "bbox": {
                        "x0": 162.94149780273438,
                        "y0": 243.44000244140625,
                        "x1": 423.47845458984375,
                        "y1": 253.28001403808594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Sequential processing Parallel processing",
                    "bbox": {
                        "x0": 162.80470275878906,
                        "y0": 259.52001953125,
                        "x1": 410.82879638671875,
                        "y1": 269.3600158691406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Centralized architectures Distributed & time-sensitive architectures",
                    "bbox": {
                        "x0": 156.71099853515625,
                        "y0": 275.5999755859375,
                        "x1": 456.71630859375,
                        "y1": 285.4399719238281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "In standard WIMP interaction style (Window, Icon, Menu, Pointing device), a",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 301.27996826171875,
                        "x1": 470.7752990722656,
                        "y1": 311.1199645996094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "singular physical input device is used to control the position of a cursor and present",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 312.79998779296875,
                        "x1": 470.6404113769531,
                        "y1": 322.6399841308594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "information organized in windows and represented with icons. In contrast, in",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 324.32000732421875,
                        "x1": 470.7092590332031,
                        "y1": 334.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal interfaces, various modalities can be used as input streams (voice,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 335.8399963378906,
                        "x1": 470.8428039550781,
                        "y1": 345.67999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "gestures, facial expressions, etc.). Further, input from graphical user interfaces is",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 347.3599853515625,
                        "x1": 470.6994323730469,
                        "y1": 357.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "generally deterministic, with either mouse position or characters typed on a keyboard",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 358.8800048828125,
                        "x1": 470.66998291015625,
                        "y1": 368.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "used to control the computer. In multimodal interfaces, input streams have to be first",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 370.3999938964844,
                        "x1": 470.82086181640625,
                        "y1": 380.239990234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interpreted by probabilistic recognizers (HMM, GMM, SOM, etc.) and thus their",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 381.91998291015625,
                        "x1": 470.74859619140625,
                        "y1": 391.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "results are weighted by a degree of uncertainty. Further, events are not always clearly",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 393.67999267578125,
                        "x1": 470.7190246582031,
                        "y1": 403.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "temporally delimited and thus require a continuous interpretation. Due to the multiple",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 405.1999816894531,
                        "x1": 470.7972412109375,
                        "y1": 415.03997802734375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "recognizers necessary to interpret multimodal input and the continuous property of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 416.7200012207031,
                        "x1": 470.6994934082031,
                        "y1": 426.55999755859375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "input streams, multimodal systems depend on time synchronized parallel processing.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 428.239990234375,
                        "x1": 470.6501770019531,
                        "y1": 438.0799865722656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Further, as we will see in the following section, the time sensitivity of multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 439.760009765625,
                        "x1": 470.8442077636719,
                        "y1": 449.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "systems is crucial to determining the order of processing multimodal commands in",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 451.2799987792969,
                        "x1": 470.6009216308594,
                        "y1": 461.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "parallel or in sequence. Finally, multimodal systems often implement a distributed",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 462.79998779296875,
                        "x1": 470.60089111328125,
                        "y1": 472.6399841308594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "architecture, to deal out the computation and insure synchronization. Multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 474.32000732421875,
                        "x1": 470.71905517578125,
                        "y1": 484.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "systems can be very resource demanding in some cases (e.g., speech/gesture",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 485.8399963378906,
                        "x1": 470.72894287109375,
                        "y1": 495.67999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "recognition, machine-learning augmented integration).",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 497.6000061035156,
                        "x1": 343.4839782714844,
                        "y1": 507.44000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "2.3 Cognitive Foundations",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 530.9599609375,
                        "x1": 241.90505981445312,
                        "y1": 540.7999877929688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The advantages of multimodal interface design are elucidated in the theory of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 553.52001953125,
                        "x1": 470.74859619140625,
                        "y1": 563.3600463867188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "cognitive psychology, as well as human-computer interaction studies, most",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 565.0400390625,
                        "x1": 470.77362060546875,
                        "y1": 574.8800659179688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "specifically in cognitive load theory, gestalt theory, and Baddeley's model of working",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 576.7999877929688,
                        "x1": 470.78887939453125,
                        "y1": 586.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "memory [5, 53, 55]. Findings in cognitive psychology reveal:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 588.3200073242188,
                        "x1": 370.7981262207031,
                        "y1": 598.1600341796875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• humans are able to process modalities partially independently and, thus, presenting information with multiple modalities increases human working",
                    "bbox": {
                        "x0": 134.04010009765625,
                        "y0": 598.4525146484375,
                        "x1": 470.8421936035156,
                        "y1": 620.8654174804688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "memory;",
                    "bbox": {
                        "x0": 152.04010009765625,
                        "y0": 621.4925537109375,
                        "x1": 188.10081481933594,
                        "y1": 632.3854370117188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• humans tend to reproduce interpersonal interaction patterns during multimodal interaction with a system;",
                    "bbox": {
                        "x0": 134.04010009765625,
                        "y0": 636.8525390625,
                        "x1": 470.803955078125,
                        "y1": 659.2654418945312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• human performance is improved when interacting multimodally due to the way human perception, communication, and memory function.",
                    "bbox": {
                        "x0": 134.04010009765625,
                        "y0": 663.9725341796875,
                        "x1": 470.67645263671875,
                        "y1": 686.3854370117188
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 204.6199951171875,
                        "y0": 195.13299560546875,
                        "x1": 391.2229919433594,
                        "y1": 205.5880126953125
                    },
                    "text_content": "Table 1. Differences between GUIs and MUIs.",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 187.61500549316406,
                        "y0": 300.97198486328125,
                        "x1": 215.3679962158203,
                        "y1": 311.427001953125
                    },
                    "text_content": "WIMP",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 246.86700439453125,
                        "y0": 312.49200439453125,
                        "x1": 373.0889892578125,
                        "y1": 322.947998046875
                    },
                    "text_content": "e is used to control the position",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 312.49200439453125,
                        "x1": 470.947998046875,
                        "y1": 334.4679870605469
                    },
                    "text_content": "singular physical input device is used to control the position of a cursor and present \ninformation organized in windows and represented with icons. In contrast, in",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 335.5320129394531,
                        "x1": 216.0919952392578,
                        "y1": 345.98699951171875
                    },
                    "text_content": "multimodal interfaces,",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 223.91000366210938,
                        "y0": 335.5320129394531,
                        "x1": 301.3949890136719,
                        "y1": 345.98699951171875
                    },
                    "text_content": "various modalities",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 335.5320129394531,
                        "x1": 471.1499938964844,
                        "y1": 357.50799560546875
                    },
                    "text_content": "multimodal interfaces, various modalities can be used as input streams (voice, \ngestures, facial expressions, etc.). Further, input from graphical user interfaces is",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 254.98599243164062,
                        "y0": 588.011962890625,
                        "x1": 371.1059875488281,
                        "y1": 598.4669799804688
                    },
                    "text_content": "cognitive psychology reveal: \nocess modalities partially in",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 243.1060028076172,
                        "y0": 596.9169921875,
                        "x1": 443.614990234375,
                        "y1": 610.64501953125
                    },
                    "text_content": "in cognitive psychology reveal: \nprocess modalities partially independently and,\nn with multiple modalities increases human w",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 151.63600158691406,
                        "y0": 608.43701171875,
                        "x1": 471.072998046875,
                        "y1": 633.6849975585938
                    },
                    "text_content": "humans are able to process modalities partially independently and, thus, \npresenting information with multiple modalities increases human working \nmemory;",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 216.7169952392578,
                        "y0": 635.3170166015625,
                        "x1": 358.3420104980469,
                        "y1": 649.0449829101562
                    },
                    "text_content": "reproduce interpersonal interaction \n a system;",
                    "comment_info": null
                }
            ],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 5,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "Multimodal Interfaces: A Survey of Principles, Models and Frameworks 5",
                    "bbox": {
                        "x0": 185.16659545898438,
                        "y0": 121.99996948242188,
                        "x1": 470.8302001953125,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "For example, when processing both auditory and visual information during speech, a",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.1199951171875,
                        "x1": 470.6896057128906,
                        "y1": 158.9600067138672
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "listener is able to extract a higher rate of lexical intelligibility (Grant & Greenberg",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 160.6400146484375,
                        "x1": 470.6694641113281,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "[24]). This section thus presents works from cognitive science related to multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 172.15997314453125,
                        "x1": 470.64208984375,
                        "y1": 181.99998474121094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interaction, following cognitive load theory, gestalt theory and Baddeley's model of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 183.91998291015625,
                        "x1": 470.80584716796875,
                        "y1": 193.75999450683594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "working memory; the section ends with the description of a framework aimed at",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 195.44000244140625,
                        "x1": 470.7209167480469,
                        "y1": 205.28001403808594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "human performance prediction.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 206.96002197265625,
                        "x1": 250.73626708984375,
                        "y1": 216.80003356933594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Mousavi et al [44] experimented with presenting students content using partly",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 218.47998046875,
                        "x1": 470.6873779296875,
                        "y1": 228.3199920654297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "auditory and partly visual modes. The split-attention effect (Sweller et al. [66]) that",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 230.0,
                        "x1": 470.8373718261719,
                        "y1": 239.8400115966797
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "resulted “suggested that working memory has partially independent processors for",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 241.52001953125,
                        "x1": 470.69146728515625,
                        "y1": 251.3600311279297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "handling visual and auditory material.” The authors argued that if working memory is",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 253.03997802734375,
                        "x1": 470.7826843261719,
                        "y1": 262.8799743652344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "a primary limitation in learning, then increasing effective working memory by",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 264.55999755859375,
                        "x1": 470.6545715332031,
                        "y1": 274.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "presenting information in a dual-mode form rather than a purely visual one, could",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 276.08001708984375,
                        "x1": 470.7498474121094,
                        "y1": 285.9200134277344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "expand processing capabilities. The results of Mousavi et al. were confirmed by",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 287.8399658203125,
                        "x1": 470.6600646972656,
                        "y1": 297.6799621582031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Tindall-Ford et al. [67], who used more general types of tasks than pure mathematical",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 299.3599853515625,
                        "x1": 470.72943115234375,
                        "y1": 309.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "ones, and by Mayer & Moreno [39] who studied the same effect with multimedia",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 310.8800048828125,
                        "x1": 470.7331848144531,
                        "y1": 320.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "learning material. All this work is in line with the cognitive load theory, which",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 322.4000244140625,
                        "x1": 470.7760925292969,
                        "y1": 332.2400207519531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "assumes a limited working memory in which all conscious learning and thinking",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 333.91998291015625,
                        "x1": 470.6305847167969,
                        "y1": 343.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "occurs, and an effectively unlimited long-term memory that holds a large number of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 345.44000244140625,
                        "x1": 470.7650146484375,
                        "y1": 355.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "automated schemas that can be brought into working memory for processing. Oviatt",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 356.9599914550781,
                        "x1": 470.8363952636719,
                        "y1": 366.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "[53] applied these findings to educational interface design in testing a number of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 368.47998046875,
                        "x1": 470.720947265625,
                        "y1": 378.3199768066406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "different user-centered design principles and strategies, showing that user-interface",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 380.0,
                        "x1": 470.8072509765625,
                        "y1": 389.8399963378906
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "design that minimizes cognitive load can free up mental resources and improve",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 391.760009765625,
                        "x1": 470.76251220703125,
                        "y1": 401.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "student performance. One strategy for accomplishing this is designing a multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 403.2799987792969,
                        "x1": 470.7387390136719,
                        "y1": 413.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interface for students.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 414.79998779296875,
                        "x1": 211.87811279296875,
                        "y1": 424.6399841308594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "In the design of map-based pen/voice interfaces, Oviatt et al. [55] demonstrated",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 426.32000732421875,
                        "x1": 470.7793884277344,
                        "y1": 436.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "that Gestalt theoretic principles successfully predicted a number of human behaviors,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 437.8399963378906,
                        "x1": 470.70733642578125,
                        "y1": 447.67999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "such as: users consistently followed a specific multimodal integration pattern (i.e.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 449.3599853515625,
                        "x1": 470.71893310546875,
                        "y1": 459.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "sequential versus simultaneous), and entrenched further in their pattern during error",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 460.8800048828125,
                        "x1": 470.65020751953125,
                        "y1": 470.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "handling when you might expect them to switch their behavior. Gestalt theory also",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 472.3999938964844,
                        "x1": 470.7034606933594,
                        "y1": 482.239990234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "correctly predicted in this study a dominant number of subjects applying simultaneous",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 484.1600036621094,
                        "x1": 470.66986083984375,
                        "y1": 494.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "integration over sequential integration.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 495.67999267578125,
                        "x1": 279.8725280761719,
                        "y1": 505.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The original short-term memory model of Baddeley & Hitch [6], refined later by",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 507.199951171875,
                        "x1": 470.7823791503906,
                        "y1": 517.0399780273438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Baddeley [5], described short-term or working memory as being composed of three",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 518.719970703125,
                        "x1": 470.7914123535156,
                        "y1": 528.5599975585938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "main components: the central executive (which acts as supervisory system and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 530.239990234375,
                        "x1": 470.7331848144531,
                        "y1": 540.0800170898438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "controls the flow of information), the phonological loop, and the visuo-spatial",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 541.760009765625,
                        "x1": 470.8332214355469,
                        "y1": 551.6000366210938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "sketchpad, with the latter two dedicated to auditory-verbal and visuo-spatial",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 553.280029296875,
                        "x1": 470.8332214355469,
                        "y1": 563.1200561523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "information processing, respectively. Although these two slave processors are",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 564.7999877929688,
                        "x1": 470.7008056640625,
                        "y1": 574.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "coordinated by a central executive, they function largely independently in terms of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 576.3200073242188,
                        "x1": 470.7533874511719,
                        "y1": 586.1600341796875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "lower-level modality processing. This model was derived from experimental findings",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 588.0800170898438,
                        "x1": 470.82037353515625,
                        "y1": 597.9200439453125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "with dual-task paradigms. Performance of two simultaneous tasks requiring the use of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 599.5999755859375,
                        "x1": 470.7576904296875,
                        "y1": 609.4400024414062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "two perceptual domains (i.e. a visual and a verbal task) were observed to be nearly as",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 611.1199951171875,
                        "x1": 470.8117370605469,
                        "y1": 620.9600219726562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "efficient as performance of individual tasks. In contrast, when a person tries to carry",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 622.6400146484375,
                        "x1": 470.7127380371094,
                        "y1": 632.4800415039062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "out two tasks simultaneously that use the same perceptual domain, performance is less",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 634.1599731445312,
                        "x1": 470.67962646484375,
                        "y1": 644.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "efficient than when performing the tasks individually. As such, human performance is",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 645.6799926757812,
                        "x1": 470.8228454589844,
                        "y1": 655.52001953125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "improved when interacting with two modalities that can be co-processed in separate",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 657.2000122070312,
                        "x1": 470.771484375,
                        "y1": 667.0400390625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "stores.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 668.719970703125,
                        "x1": 150.8302001953125,
                        "y1": 678.5599975585938
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 205.99099731445312,
                        "y0": 148.81298828125,
                        "x1": 401.4280090332031,
                        "y1": 159.26702880859375
                    },
                    "text_content": "processing both auditory and visual information",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 168.46200561523438,
                        "y0": 160.3330078125,
                        "x1": 383.3810119628906,
                        "y1": 170.7869873046875
                    },
                    "text_content": "able to extract a higher rate of lexical intelligibility",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 252.73199462890625,
                        "x1": 471.0899963378906,
                        "y1": 274.7080078125
                    },
                    "text_content": "handling visual and auditory material.” The authors argued that if working memory is \na primary limitation in learning, then increasing effective working memory by",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 333.61199951171875,
                        "x1": 470.93798828125,
                        "y1": 355.5880126953125
                    },
                    "text_content": "assumes a limited working memory in which all conscious learning and thinking \noccurs, and an effectively unlimited long-term memory that holds a large number of",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 345.13299560546875,
                        "x1": 471.0719909667969,
                        "y1": 367.10699462890625
                    },
                    "text_content": "occurs, and an effectively unlimited long-term memory that holds a large number of \nautomated schemas that can be brought into working memory for processing. Oviatt",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 255.25,
                        "y0": 356.6520080566406,
                        "x1": 440.2760009765625,
                        "y1": 367.10699462890625
                    },
                    "text_content": "brought into working memory for processing.",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 222.06500244140625,
                        "y0": 518.4119873046875,
                        "x1": 353.7170104980469,
                        "y1": 528.8670043945312
                    },
                    "text_content": "d short-term or working memory",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 518.4119873046875,
                        "x1": 471.0989990234375,
                        "y1": 540.3880004882812
                    },
                    "text_content": "Baddeley [5], described short-term or working memory as being composed of three \nmain components: the central executive (which acts as supervisory system and",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 224.98899841308594,
                        "y0": 529.9320068359375,
                        "x1": 296.6679992675781,
                        "y1": 540.3880004882812
                    },
                    "text_content": "central executive",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 296.6300048828125,
                        "y0": 541.4530029296875,
                        "x1": 373.052001953125,
                        "y1": 551.907958984375
                    },
                    "text_content": "phonological loop,",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 541.4530029296875,
                        "x1": 471.1409912109375,
                        "y1": 563.427001953125
                    },
                    "text_content": "controls the flow of information), the phonological loop, and the visuo-spatial \nsketchpad, with the latter two dedicated to auditory-verbal and visuo-spatial",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 268.6029968261719,
                        "y0": 552.9719848632812,
                        "x1": 391.2510070800781,
                        "y1": 563.427001953125
                    },
                    "text_content": "dedicated to auditory-verbal",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 246.41600036621094,
                        "y0": 552.9719848632812,
                        "x1": 261.9490051269531,
                        "y1": 563.427001953125
                    },
                    "text_content": "two",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 552.9719848632812,
                        "x1": 471.1409912109375,
                        "y1": 574.947998046875
                    },
                    "text_content": "sketchpad, with the latter two dedicated to auditory-verbal and visuo-spatial \ninformation processing, respectively. Although these two slave processors are",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 198.06399536132812,
                        "y0": 576.0130004882812,
                        "x1": 267.99200439453125,
                        "y1": 586.468017578125
                    },
                    "text_content": "central executive,",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 576.0130004882812,
                        "x1": 471.0610046386719,
                        "y1": 598.2269897460938
                    },
                    "text_content": "coordinated by a central executive, they function largely independently in terms of \nlower-level modality processing. This model was derived from experimental findings",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 296.16400146484375,
                        "y0": 599.2919921875,
                        "x1": 389.8160095214844,
                        "y1": 609.7470092773438
                    },
                    "text_content": "two simultaneous tasks",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 610.81201171875,
                        "x1": 221.38600158691406,
                        "y1": 621.2680053710938
                    },
                    "text_content": "two perceptual domains",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 633.8519897460938,
                        "x1": 241.0659942626953,
                        "y1": 644.3070068359375
                    },
                    "text_content": "out two tasks simultaneously",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 260.5350036621094,
                        "y0": 633.8519897460938,
                        "x1": 388.78399658203125,
                        "y1": 644.3070068359375
                    },
                    "text_content": "use the same perceptual domain,",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 633.8519897460938,
                        "x1": 470.98699951171875,
                        "y1": 655.8270263671875
                    },
                    "text_content": "out two tasks simultaneously that use the same perceptual domain, performance is less \nefficient than when performing the tasks individually. As such, human performance is",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 656.8919677734375,
                        "x1": 163.5760040283203,
                        "y1": 667.3469848632812
                    },
                    "text_content": "improved",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 258.92999267578125,
                        "y0": 656.8919677734375,
                        "x1": 319.5400085449219,
                        "y1": 667.3469848632812
                    },
                    "text_content": "two modalities",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 656.8919677734375,
                        "x1": 471.0790100097656,
                        "y1": 678.8679809570312
                    },
                    "text_content": "improved when interacting with two modalities that can be co-processed in separate \nstores.",
                    "comment_info": null
                }
            ],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 6,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "6 Bruno Dumas1, Denis Lalanne1, Sharon Oviatt2",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 121.99996948242188,
                        "x1": 329.2164001464844,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Wickens [72][73] also developed a framework, the “multiple resource model”,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 149.1199951171875,
                        "x1": 470.8298034667969,
                        "y1": 158.9600067138672
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "aimed at performance prediction involving coordination between user input and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 160.6400146484375,
                        "x1": 470.6502990722656,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "system output modes for different types of tasks. This model suggests that four",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 172.15997314453125,
                        "x1": 470.64031982421875,
                        "y1": 181.99998474121094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "different dimensions are to be taken into account when predicting coordination versus",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 183.91998291015625,
                        "x1": 470.8250732421875,
                        "y1": 193.75999450683594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interference during human task processing involving different modes. The four",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 195.44000244140625,
                        "x1": 470.7388000488281,
                        "y1": 205.28001403808594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "dimensions considered are stages (perceptual/cognitive vs. response), sensory",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 206.96002197265625,
                        "x1": 470.6403503417969,
                        "y1": 216.80003356933594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modalities (auditory vs. visual), codes (visual vs. spatial) and channels of visual",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 218.47998046875,
                        "x1": 470.7486267089844,
                        "y1": 228.3199920654297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "information (focal vs. ambient).",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 230.0,
                        "x1": 252.44285583496094,
                        "y1": 239.8400115966797
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "2.4 Seminal Works, Findings and Guidelines",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 263.3599853515625,
                        "x1": 319.6312255859375,
                        "y1": 273.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Multimodal interfaces emerged approximately 30 years ago within the field of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 286.15997314453125,
                        "x1": 470.8096923828125,
                        "y1": 295.9999694824219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "human/computer interaction with Richard Bolt’s “Put-That-There” application [9],",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 297.67999267578125,
                        "x1": 470.84600830078125,
                        "y1": 307.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "which was created in 1980. First multimodal systems sought ways to go beyond the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 309.20001220703125,
                        "x1": 470.8159484863281,
                        "y1": 319.0400085449219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "standard interaction mode at this time, which was graphical interfaces with keyboards",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 320.719970703125,
                        "x1": 470.8117980957031,
                        "y1": 330.5599670410156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and mice. Bolt’s “Put-that-there” processed spoken commands linked to a pointing",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 332.239990234375,
                        "x1": 470.79864501953125,
                        "y1": 342.0799865722656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "gesture using an armrest-mounted touchpad to move and change shapes displayed on",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 343.760009765625,
                        "x1": 470.7101135253906,
                        "y1": 353.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "a screen in front of the user. Since this seminal work, multimodal interaction",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 355.2799987792969,
                        "x1": 470.6697692871094,
                        "y1": 365.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "practitioners have strived to integrate more modalities, to refine hardware and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 367.0400085449219,
                        "x1": 470.6207580566406,
                        "y1": 376.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "software components, and to explore limits and capabilities of multimodal interfaces.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 378.55999755859375,
                        "x1": 470.7343444824219,
                        "y1": 388.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Historically, the main trend has focused on pointing and speech combined using",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 390.0799865722656,
                        "x1": 470.7411193847656,
                        "y1": 399.91998291015625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "speech/mouse, speech/pen [17], speech/gesture [45], or speech/gaze tracking [31].",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 401.6000061035156,
                        "x1": 470.84600830078125,
                        "y1": 411.44000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Later multimodal interfaces evolved beyond pointing into richer interaction, allowing",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 413.1199951171875,
                        "x1": 470.6501159667969,
                        "y1": 422.9599914550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "users to produce symbolic gestures such as arrows and encircling.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 424.6399841308594,
                        "x1": 388.1320495605469,
                        "y1": 434.47998046875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Another direction in multimodal research has been speech/lip movement",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 436.1600036621094,
                        "x1": 470.8263244628906,
                        "y1": 446.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "integration [57][12], driven by cognitive science research in intersensory audio-visual",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 447.67999267578125,
                        "x1": 470.83599853515625,
                        "y1": 457.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "perception. This kind of work has included classification of human lip movement",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 459.1999816894531,
                        "x1": 470.709228515625,
                        "y1": 469.03997802734375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "(visemes) and the viseme-phoneme mappings that occur during articulated speech.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 470.9599914550781,
                        "x1": 470.77056884765625,
                        "y1": 480.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Such work has contributed improving robustness of speech recognition in noisy",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 482.47998046875,
                        "x1": 470.7190856933594,
                        "y1": 492.3199768066406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "environments. For more details about these systems, see [8].",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 494.0,
                        "x1": 366.3387145996094,
                        "y1": 503.8399963378906
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Table 2. 10 myths of multimodal interaction (We acknowledge ACM for allowing the",
                    "bbox": {
                        "x0": 128.3997039794922,
                        "y0": 517.0400390625,
                        "x1": 467.44122314453125,
                        "y1": 526.8800659179688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "reprint of this table).",
                    "bbox": {
                        "x0": 256.30010986328125,
                        "y0": 528.5599975585938,
                        "x1": 339.5366516113281,
                        "y1": 538.4000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Myth #1: If you build a multimodal system, users will interact multimodally.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 547.52001953125,
                        "x1": 430.2637939453125,
                        "y1": 557.3600463867188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Myth #2: Speech and pointing is the dominant multimodal integration pattern.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 559.280029296875,
                        "x1": 439.1504821777344,
                        "y1": 569.1200561523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Myth #3: Multimodal input involves simultaneous signals.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 570.7999877929688,
                        "x1": 358.0517883300781,
                        "y1": 580.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Myth #4: Speech is the primary input mode in any multimodal system that includes it.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 582.3200073242188,
                        "x1": 467.46099853515625,
                        "y1": 592.1600341796875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Myth #5: Multimodal language does not differ linguistically from unimodal language.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 593.8399658203125,
                        "x1": 469.70709228515625,
                        "y1": 603.6799926757812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Myth #6: Multimodal integration involves redundancy of content between modes.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 605.3599853515625,
                        "x1": 451.0547790527344,
                        "y1": 615.2000122070312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Myth #7: Individual error-prone recognition technologies combine multimodally to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 616.8800048828125,
                        "x1": 470.7687683105469,
                        "y1": 626.7200317382812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "produce even greater unreliability.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 628.4000244140625,
                        "x1": 264.96099853515625,
                        "y1": 638.2400512695312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Myth #8: All users’ multimodal commands are integrated in a uniform way.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 639.9199829101562,
                        "x1": 428.8769836425781,
                        "y1": 649.760009765625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Myth #9: Different input modes are capable of transmitting comparable content.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 651.6799926757812,
                        "x1": 448.0224914550781,
                        "y1": 661.52001953125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Myth #10: Enhanced efficiency is the main advantage of multimodal systems.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 663.2000122070312,
                        "x1": 434.6680908203125,
                        "y1": 673.0400390625
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 313.0799865722656,
                        "y0": 160.3330078125,
                        "x1": 364.1340026855469,
                        "y1": 170.7869873046875
                    },
                    "text_content": "coordination",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 402.29901123046875,
                        "y0": 160.3330078125,
                        "x1": 451.0899963378906,
                        "y1": 170.7869873046875
                    },
                    "text_content": "n user input",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 171.85198974609375,
                        "x1": 214.68499755859375,
                        "y1": 182.3070068359375
                    },
                    "text_content": "system output modes",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 195.13299560546875,
                        "x1": 471.0559997558594,
                        "y1": 240.14697265625
                    },
                    "text_content": "interference during human task processing involving different modes. The four \ndimensions considered are stages (perceptual/cognitive vs. response), sensory \nmodalities (auditory vs. visual), codes (visual vs. spatial) and channels of visual \ninformation (focal vs. ambient).",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 163.3699951171875,
                        "y0": 516.7319946289062,
                        "x1": 304.4179992675781,
                        "y1": 527.18798828125
                    },
                    "text_content": "10 myths of multimodal interaction",
                    "comment_info": null
                }
            ],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 7,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "Multimodal Interfaces: A Survey of Principles, Models and Frameworks 7",
                    "bbox": {
                        "x0": 185.16659545898438,
                        "y0": 121.99996948242188,
                        "x1": 470.8302001953125,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "In the course of the last decade, researchers have highlighted particular empirical",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.1199951171875,
                        "x1": 470.689453125,
                        "y1": 158.9600067138672
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "findings that have guided the design of multimodal interfaces compared to other sorts",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 160.6400146484375,
                        "x1": 470.738525390625,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "of human-computer interfaces. Key findings are illustrated in the following “10",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 172.15997314453125,
                        "x1": 470.6806640625,
                        "y1": 181.99998474121094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "myths” shown in Table 2, which exposed common engineering myths regarding how",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 183.91998291015625,
                        "x1": 470.6797180175781,
                        "y1": 193.75999450683594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "people interact multimodally [52]. Based on empirical findings, Oviatt distilled",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 195.44000244140625,
                        "x1": 470.7193298339844,
                        "y1": 205.28001403808594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "implications for how more effective multimodal interfaces could be designed.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 206.96002197265625,
                        "x1": 435.8953552246094,
                        "y1": 216.80003356933594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "In more recent years, research has also focused on mainstreaming multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 230.0,
                        "x1": 470.6697692871094,
                        "y1": 239.8400115966797
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interfaces. In this trend, Reeves et al. defined the following “guidelines for",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 241.52001953125,
                        "x1": 470.82098388671875,
                        "y1": 251.3600311279297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal user interface design” [59]:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 253.03997802734375,
                        "x1": 282.7274475097656,
                        "y1": 262.8799743652344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Multimodal systems should be designed for the broadest range of users and contexts of use, since the availability of multiple modalities supports flexibility. For",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 263.1725769042969,
                        "x1": 470.8355407714844,
                        "y1": 285.58544921875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "example, the same user may benefit from speech input in a car, but pen input in a",
                    "bbox": {
                        "x0": 134.04010009765625,
                        "y0": 286.2125549316406,
                        "x1": 470.71868896484375,
                        "y1": 297.10540771484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "noisy environment.",
                    "bbox": {
                        "x0": 134.04010009765625,
                        "y0": 297.7325744628906,
                        "x1": 211.17588806152344,
                        "y1": 308.62542724609375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Designers should take care to address privacy and security issues when creating multimodal systems: speech, for example, should not be used as a modality to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 313.3325500488281,
                        "x1": 470.8044128417969,
                        "y1": 335.74542236328125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "convey private or personal information in public contexts.",
                    "bbox": {
                        "x0": 134.04010009765625,
                        "y0": 336.132568359375,
                        "x1": 366.1631774902344,
                        "y1": 347.0254211425781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Modalities should be integrated in a manner compatible with user preferences and capabilities, for example, combining complementary audio and visual modes that",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 351.7325744628906,
                        "x1": 470.7405700683594,
                        "y1": 374.1454162597656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "users can co-process more easily.",
                    "bbox": {
                        "x0": 134.04010009765625,
                        "y0": 374.7725830078125,
                        "x1": 267.55499267578125,
                        "y1": 385.6654357910156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Multimodal systems should be designed to adapt easily to different contexts, user profiles and application needs.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 390.132568359375,
                        "x1": 470.7486267089844,
                        "y1": 412.5454406738281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Error prevention and handling is a major advantage of multimodal interface design, for both user- and system-centered reasons. Specific guidelines include integrating",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 417.2525634765625,
                        "x1": 470.7520446777344,
                        "y1": 439.6654357910156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "complementary modalities to improve system robustness, and giving users better",
                    "bbox": {
                        "x0": 134.04010009765625,
                        "y0": 440.2925720214844,
                        "x1": 470.6368103027344,
                        "y1": 451.1854248046875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "control over modality selection so they can avoid errors.",
                    "bbox": {
                        "x0": 134.04010009765625,
                        "y0": 451.81256103515625,
                        "x1": 359.1005554199219,
                        "y1": 462.7054138183594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "3 Principles of User-Computer Multimodal Interaction",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 494.5400085449219,
                        "x1": 411.85430908203125,
                        "y1": 506.5400085449219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The driving principles of multimodal interaction are well described in numerous",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 522.5599975585938,
                        "x1": 470.7315979003906,
                        "y1": 532.4000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "surveys [8][26][51][54][62]. The following concepts are popularly accepted: fusion",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 534.0799560546875,
                        "x1": 470.78594970703125,
                        "y1": 543.9199829101562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "(also called multimodal signal integration), fission (also called response planning),",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 545.5999755859375,
                        "x1": 470.6501770019531,
                        "y1": 555.4400024414062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "dialog management, context management and time-sensitive architectures. In the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 557.1199951171875,
                        "x1": 470.7462158203125,
                        "y1": 566.9600219726562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "following subsections, we introduce these concepts, at a high level first to illustrate",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 568.6400146484375,
                        "x1": 470.79608154296875,
                        "y1": 578.4800415039062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "how they are organized around a common conceptual architecture, and later at a lower",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 580.1599731445312,
                        "x1": 470.7682189941406,
                        "y1": 590.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "level to probe key principles.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 591.6799926757812,
                        "x1": 241.2997283935547,
                        "y1": 601.52001953125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "3.1 Theoretical Principles",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 625.0399780273438,
                        "x1": 239.11050415039062,
                        "y1": 634.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Inspired by Norman’s action cycle [47], and based on well accepted findings and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 647.8399658203125,
                        "x1": 470.8067626953125,
                        "y1": 657.6799926757812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "taxonomies, the following model of multimodal man-machine communication can be",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 659.3599853515625,
                        "x1": 470.77691650390625,
                        "y1": 669.2000122070312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "drawn, together with the major concepts that should be considered when building a",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 670.8800048828125,
                        "x1": 470.70928955078125,
                        "y1": 680.7200317382812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal system (Figure 1): the fusion of multimodal inputs, and the multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 682.4000244140625,
                        "x1": 470.69940185546875,
                        "y1": 692.2400512695312
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 533.77197265625,
                        "x1": 471.0929870605469,
                        "y1": 555.7470092773438
                    },
                    "text_content": "surveys [8][26][51][54][62]. The following concepts are popularly accepted: fusion \n(also called multimodal signal integration), fission (also called response planning),",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 556.81298828125,
                        "x1": 440.0379943847656,
                        "y1": 567.2680053710938
                    },
                    "text_content": "dialog management, context management and time-sensitive architectures.",
                    "comment_info": null
                }
            ],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 8,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "8 Bruno Dumas1, Denis Lalanne1, Sharon Oviatt2",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 121.99996948242188,
                        "x1": 329.2164001464844,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "fission to generate an adequate message to the user, according to the context of use,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.1199951171875,
                        "x1": 470.7852478027344,
                        "y1": 158.9600067138672
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "preferences and profile.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 160.6400146484375,
                        "x1": 219.6418914794922,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Fig. 1. A representation of multimodal man machine interaction loop.",
                    "bbox": {
                        "x0": 158.2581024169922,
                        "y0": 385.760009765625,
                        "x1": 437.5321350097656,
                        "y1": 395.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "When a human interacts with a machine, his communication can be divided in four",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 409.0400085449219,
                        "x1": 470.8355407714844,
                        "y1": 418.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "different states. The first state is a decision state, in which the communication",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 420.55999755859375,
                        "x1": 470.7628173828125,
                        "y1": 430.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "message content is prepared consciously for an intention, or unconsciously for",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 432.0799865722656,
                        "x1": 470.66015625,
                        "y1": 441.91998291015625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "attentional content or emotions. The second state is the action state, where the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 443.6000061035156,
                        "x1": 470.8128967285156,
                        "y1": 453.44000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "communication means to transmit the message are selected, such as speech, gestures",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 455.1199951171875,
                        "x1": 470.6855163574219,
                        "y1": 464.9599914550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "or facial expressions. The machine, in turn, will make use of a number of different",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 466.6399841308594,
                        "x1": 470.7584533691406,
                        "y1": 476.47998046875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modules to grasp the most information possible from a user, and will have similarly",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 478.1600036621094,
                        "x1": 470.61077880859375,
                        "y1": 488.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "four main states (Figure 1). At first, the messages are interpreted in the perception",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 489.67999267578125,
                        "x1": 470.7927551269531,
                        "y1": 499.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "state, where the multimodal system receives information from one or multiple",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 501.1999816894531,
                        "x1": 470.7130126953125,
                        "y1": 511.03997802734375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "sensors, at one or multiple levels of expression. In the interpretation state, the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 512.9599609375,
                        "x1": 470.81878662109375,
                        "y1": 522.7999877929688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal system will try to give some meaning to the different information it",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 524.47998046875,
                        "x1": 470.71990966796875,
                        "y1": 534.3200073242188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "collected in the perception state. This is typically the place where fusion of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 536.0,
                        "x1": 470.65020751953125,
                        "y1": 545.8400268554688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal messages takes place. Further, in the computational state, action is taken",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 547.52001953125,
                        "x1": 470.7867736816406,
                        "y1": 557.3600463867188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "following the business logic and dialogue manager rules defined by the developer.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 559.0400390625,
                        "x1": 470.7638244628906,
                        "y1": 568.8800659179688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Depending on the meaning extracted in the interpretation state, an answer is generated",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 570.5599975585938,
                        "x1": 470.669921875,
                        "y1": 580.4000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and transmitted in the action state, in which a fission engine will determine the most",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 582.0800170898438,
                        "x1": 470.7546691894531,
                        "y1": 591.9200439453125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "relevant modalities to return the message, depending on the context of use (e.g. in the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 593.5999755859375,
                        "x1": 470.7530517578125,
                        "y1": 603.4400024414062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "car, office, etc.) and the profile of the user (blind user, elderly, etc.).",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 605.3599853515625,
                        "x1": 396.732177734375,
                        "y1": 615.2000122070312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "3.2 Computational Architecture and Key Components",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 638.719970703125,
                        "x1": 361.02301025390625,
                        "y1": 648.5599975585938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The previous section illustrated multimodal man-machine interaction underlying",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 661.280029296875,
                        "x1": 470.8102111816406,
                        "y1": 671.1200561523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "features. In this section, we describe multimodal interaction from the machine side,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 672.7999877929688,
                        "x1": 470.7388000488281,
                        "y1": 682.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and the major software components that a multimodal system should contain. The",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 684.3200073242188,
                        "x1": 470.7191162109375,
                        "y1": 694.1600341796875
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 124.73300170898438,
                        "y0": 408.73199462890625,
                        "x1": 471.14300537109375,
                        "y1": 430.7080078125
                    },
                    "text_content": "When a human interacts with a machine, his communication can be divided in four \ndifferent states. The first state is a decision state, in which the communication",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 215.45700073242188,
                        "y0": 420.25299072265625,
                        "x1": 340.5580139160156,
                        "y1": 430.7080078125
                    },
                    "text_content": "first state is a decision state,",
                    "comment_info": null
                },
                {
                    "type": "highlight",
                    "bbox": {
                        "x0": 285.67498779296875,
                        "y0": 443.2919921875,
                        "x1": 421.4460144042969,
                        "y1": 453.74700927734375
                    },
                    "text_content": "second state is the action state,",
                    "comment_info": null
                }
            ],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 9,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "Multimodal Interfaces: A Survey of Principles, Models and Frameworks 9",
                    "bbox": {
                        "x0": 185.16659545898438,
                        "y0": 121.99996948242188,
                        "x1": 470.8302001953125,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "generic components for handling of multimodal integration are: a fusion engine, a",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.1199951171875,
                        "x1": 470.7093200683594,
                        "y1": 158.9600067138672
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "fission module, a dialog manager and a context manager, which all together form",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 160.6400146484375,
                        "x1": 470.61431884765625,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "what is called the “integration committee”. Figure 2 illustrates the processing flow",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 172.15997314453125,
                        "x1": 470.58135986328125,
                        "y1": 181.99998474121094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "between these components, the input and output modalities, as well as the potential",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 183.91998291015625,
                        "x1": 470.6600036621094,
                        "y1": 193.75999450683594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "client applications. As illustrated in the figure, input modalities are first perceived",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 195.44000244140625,
                        "x1": 470.6324157714844,
                        "y1": 205.28001403808594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "though various recognizers, which output their results to the fusion engine, in charge",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 206.96002197265625,
                        "x1": 470.7994079589844,
                        "y1": 216.80003356933594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "of giving a common interpretation of the inputs. The various levels at which",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 218.47998046875,
                        "x1": 470.6994323730469,
                        "y1": 228.3199920654297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "recognizers’ results can be fused are described in the next section, together with the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 230.0,
                        "x1": 470.69720458984375,
                        "y1": 239.8400115966797
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "various fusion mechanisms. When the fusion engine comes to an interpretation, it",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 241.52001953125,
                        "x1": 470.659912109375,
                        "y1": 251.3600311279297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "communicates it to the dialog manager, in charge of identifying the dialog state, the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 253.03997802734375,
                        "x1": 470.785400390625,
                        "y1": 262.8799743652344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "transition to perform, the action to communicate to a given application, and/or the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 264.55999755859375,
                        "x1": 470.70343017578125,
                        "y1": 274.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "message to return through the fission component. The fission engine is finally in",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 276.08001708984375,
                        "x1": 470.7376708984375,
                        "y1": 285.9200134277344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "charge of returning a message to the user through the most adequate modality or",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 287.8399658203125,
                        "x1": 470.699462890625,
                        "y1": 297.6799621582031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "combination of modalities, depending on the user profile and context of use. For this",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 299.3599853515625,
                        "x1": 470.73779296875,
                        "y1": 309.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "reason, the context manager, in charge of tracking the location, context and user",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 310.8800048828125,
                        "x1": 470.77484130859375,
                        "y1": 320.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "profile, closely communicates any changes in the environment to the three other",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 322.4000244140625,
                        "x1": 470.73870849609375,
                        "y1": 332.2400207519531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "components, so that they can adapt their interpretations.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 333.91998291015625,
                        "x1": 348.5028076171875,
                        "y1": 343.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Fig 2. The architecture of a multimodal system, with the central integration",
                    "bbox": {
                        "x0": 152.4073028564453,
                        "y0": 654.3200073242188,
                        "x1": 454.6668395996094,
                        "y1": 664.1600341796875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "committee and its major software components.",
                    "bbox": {
                        "x0": 204.639892578125,
                        "y0": 665.8399658203125,
                        "x1": 391.1767272949219,
                        "y1": 675.6799926757812
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [
                {
                    "type": "figure",
                    "bbox": {
                        "x0": 125.04000091552734,
                        "y0": 355.22003173828125,
                        "x1": 470.8800048828125,
                        "y1": 652.5800170898438
                    },
                    "vlm_description": "The image is a flowchart diagram that illustrates a process involving input and output modalities, and their interaction with various system components.\n\n1. **Input Modalities**:\n   - Located in the top left, represented by two downward arrows.\n   - Connected to \"Modalities Recognizers & Processors\" using circles.\n\n2. **Output Modalities**:\n   - Located in the top right, represented by two upward arrows.\n   - Connected to \"Modalities Synthesizers\" using circles.\n\n3. **Main System Components**:\n   - **Input Modalities Fusion**: Combines input from various modalities.\n   - **Output Modalities Fission**: Distributes information to different output modalities.\n   - **Context User Model History**: Central component storing contextual information, user models, and history, influencing other components.\n   - **Dialog Management**: Manages the interaction flow and connects to applications.\n\n4. **Integration Committee**:\n   - Connects to the components like Input/Output Modalities Fusion/Fission and Context User Model History.\n\n5. **Applications**:\n   - Positioned at the bottom, connected to Dialog Management, representing the final interaction or result delivered to users.\n\nArrows between these elements indicate the flow of information, integration, and feedback loops essential for a system that processes and responds to multi-modal inputs and outputs.",
                    "vlm_structured_data": null,
                    "associated_text_indices": null
                }
            ],
            "image_path": null
        },
        {
            "page_number": 10,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "10 Bruno Dumas1, Denis Lalanne1, Sharon Oviatt2",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 121.99996948242188,
                        "x1": 333.7164001464844,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "3.3 Fusion of Input Modalities",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 148.8800048828125,
                        "x1": 258.599365234375,
                        "y1": 158.7200164794922
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Fusion of input modalities is one of the features that distinguish multimodal interfaces",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 171.67999267578125,
                        "x1": 470.8157043457031,
                        "y1": 181.52000427246094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "from unimodal interfaces. The goal of fusion is to extract meaning from a set of input",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 183.20001220703125,
                        "x1": 470.69940185546875,
                        "y1": 193.04002380371094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modalities and pass it to a human-machine dialog manager. Fusion of different",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 194.719970703125,
                        "x1": 470.8065490722656,
                        "y1": 204.5599822998047
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modalities is a delicate task, which can be executed at three levels: at data level, at",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 206.239990234375,
                        "x1": 470.8393249511719,
                        "y1": 216.0800018310547
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "feature level and at decision level. Three different types of architectures can in turn",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 218.0,
                        "x1": 470.6402893066406,
                        "y1": 227.8400115966797
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "manage decision-level fusion: frames-based architectures, unification-based",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 229.52001953125,
                        "x1": 470.8028259277344,
                        "y1": 239.3600311279297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "architectures or hybrid symbolic/statistical fusion architectures.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 241.03997802734375,
                        "x1": 378.6266784667969,
                        "y1": 250.87998962402344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Fig 3. The various levels of multimodal fusion.",
                    "bbox": {
                        "x0": 210.17340087890625,
                        "y0": 335.1199951171875,
                        "x1": 397.002685546875,
                        "y1": 344.9599914550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Sharma et al. [62] consider these three levels for fusion of incoming data. Each",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 358.1600036621094,
                        "x1": 470.75048828125,
                        "y1": 368.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "fusion scheme functions at a different level of analysis of the same modality channel.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 369.67999267578125,
                        "x1": 470.7962951660156,
                        "y1": 379.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "As a classic illustration, consider the speech channel: data from this channel can be",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 381.1999816894531,
                        "x1": 470.75079345703125,
                        "y1": 391.03997802734375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "processed at the audio signal level, at the phoneme (feature) level, or at the semantic",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 392.7200012207031,
                        "x1": 470.7839660644531,
                        "y1": 402.55999755859375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "(decision) level (Figure 3).",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 404.47998046875,
                        "x1": 232.19322204589844,
                        "y1": 414.3199768066406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Data-level fusion is used when dealing with multiple signals coming from a very",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 416.0,
                        "x1": 470.8060302734375,
                        "y1": 426.3221740722656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "similar modality source (e.g., two webcams recording the same scene from",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 427.5199890136719,
                        "x1": 470.68157958984375,
                        "y1": 437.3599853515625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "different viewpoints). With this fusion scheme, no loss of information occurs, as",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 439.0400085449219,
                        "x1": 470.73138427734375,
                        "y1": 448.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "the signal is directly processed. This benefit is also the main shortcoming of data-",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 450.55999755859375,
                        "x1": 470.8221435546875,
                        "y1": 460.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "level fusion. Due to the absence of pre-processing, it is highly susceptible to noise",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 462.0799865722656,
                        "x1": 470.71856689453125,
                        "y1": 471.91998291015625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and failure.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 473.6000061035156,
                        "x1": 181.8706817626953,
                        "y1": 483.44000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Feature-level fusion is a common type of fusion when tightly-coupled or time",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 485.1199951171875,
                        "x1": 470.80377197265625,
                        "y1": 495.4421691894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "synchronized modalities are to be fused. The standard example is the fusion of",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 496.6399841308594,
                        "x1": 470.7137756347656,
                        "y1": 506.47998046875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "speech and lip movements. Feature-level fusion is susceptible to low-level",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 508.4000244140625,
                        "x1": 470.8414306640625,
                        "y1": 518.2400512695312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "information loss, although it handles noise better. The most classic architectures",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 519.9199829101562,
                        "x1": 470.7836608886719,
                        "y1": 529.760009765625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "used for this type of fusion are adaptive systems like artificial neural networks,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 531.4400024414062,
                        "x1": 470.7334289550781,
                        "y1": 541.280029296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Gaussian mixture models, or hidden Markov models. The use of these types of",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 542.9599609375,
                        "x1": 470.8345642089844,
                        "y1": 552.7999877929688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "adaptive architecture also means that feature-level fusion systems need numerous",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 554.47998046875,
                        "x1": 470.76220703125,
                        "y1": 564.3200073242188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "data training sets before they can achieve satisfactory performance.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 566.0,
                        "x1": 405.3950500488281,
                        "y1": 575.8400268554688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Decision-level fusion is the most common type of fusion in multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 577.52001953125,
                        "x1": 470.82318115234375,
                        "y1": 587.8421630859375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "applications. The main reason is its ability to manage loosely-coupled modalities",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 589.0399780273438,
                        "x1": 470.7913513183594,
                        "y1": 598.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "like, for example, pen and speech interaction. Failure and noise sensitivity is low",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 600.5599975585938,
                        "x1": 470.7682800292969,
                        "y1": 610.4000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "with decision-level feature, since the data has been preprocessed. On one hand, this",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 612.3200073242188,
                        "x1": 470.81402587890625,
                        "y1": 622.1600341796875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "means that decision-level fusion has to rely on the quality of previous processing.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 623.8399658203125,
                        "x1": 470.7250061035156,
                        "y1": 633.6799926757812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "On the other hand, unification-based decision-level fusion has the major benefit of",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 635.3599853515625,
                        "x1": 470.7661437988281,
                        "y1": 645.2000122070312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "improving reliability and accuracy of semantic interpretation, by combining partial",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 646.8800048828125,
                        "x1": 470.8474426269531,
                        "y1": 656.7200317382812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "semantic information coming from each input mode which can yield “mutual",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 658.4000244140625,
                        "x1": 470.7138977050781,
                        "y1": 668.2400512695312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "disambiguation” [49].",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 669.9199829101562,
                        "x1": 224.10972595214844,
                        "y1": 679.760009765625
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [
                {
                    "type": "figure",
                    "bbox": {
                        "x0": 125.04000091552734,
                        "y0": 262.3399963378906,
                        "x1": 470.6400146484375,
                        "y1": 333.3800048828125
                    },
                    "vlm_description": "The image shows a diagram illustrating a bimodal speech recognition system that integrates both visual and audio data.\n\n1. **Visual Data Processing:**\n   - A camera captures visual data.\n   - This data undergoes visual feature extraction to identify relevant features.\n   - The extracted features are used for visual-only speech recognition, leading to a decision.\n   - Visual features are also fed into a feature-level fusion process.\n\n2. **Audio Data Processing:**\n   - A microphone captures audio data.\n   - This data undergoes audio feature extraction to identify relevant features.\n   - The extracted features are used for audio-only speech recognition, leading to a decision.\n   - Audio features are also fed into a feature-level fusion process.\n\n3. **Fusion Processes:**\n   - **Feature-Level Fusion:** Combines features from both visual and audio data streams.\n   - **Decision-Level Fusion:** Combines decisions from the visual-only and audio-only recognition, leading to a final decision.\n\nThe diagram highlights how both visual and audio inputs are integrated to enhance speech recognition accuracy.",
                    "vlm_structured_data": null,
                    "associated_text_indices": null
                }
            ],
            "image_path": null
        },
        {
            "page_number": 11,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "Multimodal Interfaces: A Survey of Principles, Models and Frameworks 11",
                    "bbox": {
                        "x0": 180.66659545898438,
                        "y0": 121.99996948242188,
                        "x1": 470.8323669433594,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Table 3 below summarizes the three fusion levels, their characteristics, sensitivity to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.1199951171875,
                        "x1": 470.6303405761719,
                        "y1": 158.9600067138672
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "noise, and usage contexts.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 160.6400146484375,
                        "x1": 229.09812927246094,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Table 3. Characteristics of fusion levels.",
                    "bbox": {
                        "x0": 216.99839782714844,
                        "y0": 183.91998291015625,
                        "x1": 378.8200378417969,
                        "y1": 193.75999450683594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Data-level fusion Features-level fusion Decision-level",
                    "bbox": {
                        "x0": 208.29469299316406,
                        "y0": 196.63998413085938,
                        "x1": 455.1982421875,
                        "y1": 205.51998901367188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "fusion",
                    "bbox": {
                        "x0": 417.03961181640625,
                        "y0": 206.95999145507812,
                        "x1": 440.49169921875,
                        "y1": 215.83999633789062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Input type Raw data of same type Closely coupled",
                    "bbox": {
                        "x0": 130.5601043701172,
                        "y0": 225.43997192382812,
                        "x1": 366.1690368652344,
                        "y1": 234.31997680664062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modalities",
                    "bbox": {
                        "x0": 318.3428039550781,
                        "y0": 235.75997924804688,
                        "x1": 355.8075256347656,
                        "y1": 244.63998413085938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Loosely coupled",
                    "bbox": {
                        "x0": 398.9276123046875,
                        "y0": 225.43997192382812,
                        "x1": 458.6119689941406,
                        "y1": 234.31997680664062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modalities",
                    "bbox": {
                        "x0": 410.04791259765625,
                        "y0": 235.75997924804688,
                        "x1": 447.51263427734375,
                        "y1": 244.63998413085938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Level of",
                    "bbox": {
                        "x0": 130.5601043701172,
                        "y0": 254.24002075195312,
                        "x1": 161.26715087890625,
                        "y1": 263.1200256347656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "information",
                    "bbox": {
                        "x0": 130.5601043701172,
                        "y0": 264.5599670410156,
                        "x1": 176.5141143798828,
                        "y1": 273.4399719238281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Highest level of",
                    "bbox": {
                        "x0": 211.86529541015625,
                        "y0": 254.24002075195312,
                        "x1": 269.3277587890625,
                        "y1": 263.1200256347656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "information detail",
                    "bbox": {
                        "x0": 208.24200439453125,
                        "y0": 264.5599670410156,
                        "x1": 272.9772033691406,
                        "y1": 273.4399719238281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Moderate level of",
                    "bbox": {
                        "x0": 305.10211181640625,
                        "y0": 254.24002075195312,
                        "x1": 369.03204345703125,
                        "y1": 263.1200256347656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "information detail",
                    "bbox": {
                        "x0": 304.72198486328125,
                        "y0": 264.5599670410156,
                        "x1": 369.4571838378906,
                        "y1": 273.4399719238281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Mutual disambigua-",
                    "bbox": {
                        "x0": 392.4193115234375,
                        "y0": 254.24002075195312,
                        "x1": 465.1175231933594,
                        "y1": 263.1200256347656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "tion by combining",
                    "bbox": {
                        "x0": 395.79638671875,
                        "y0": 264.5599670410156,
                        "x1": 461.75701904296875,
                        "y1": 273.4399719238281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "data from modes",
                    "bbox": {
                        "x0": 398.5517883300781,
                        "y0": 274.8799743652344,
                        "x1": 458.9979553222656,
                        "y1": 283.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Noise/failures",
                    "bbox": {
                        "x0": 130.5601043701172,
                        "y0": 286.1600036621094,
                        "x1": 183.03201293945312,
                        "y1": 295.0400085449219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "sensitivity",
                    "bbox": {
                        "x0": 130.5601043701172,
                        "y0": 296.4800109863281,
                        "x1": 169.01939392089844,
                        "y1": 305.3600158691406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Highly susceptible to",
                    "bbox": {
                        "x0": 202.3643035888672,
                        "y0": 286.1600036621094,
                        "x1": 278.82110595703125,
                        "y1": 295.0400085449219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "noise or failures",
                    "bbox": {
                        "x0": 211.61700439453125,
                        "y0": 296.4800109863281,
                        "x1": 269.5767517089844,
                        "y1": 305.3600158691406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Less sensitive to noise",
                    "bbox": {
                        "x0": 296.7195129394531,
                        "y0": 286.1600036621094,
                        "x1": 377.4120788574219,
                        "y1": 295.0400085449219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "or failures",
                    "bbox": {
                        "x0": 318.7207946777344,
                        "y0": 296.4800109863281,
                        "x1": 355.43072509765625,
                        "y1": 305.3600158691406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Highly resistant to",
                    "bbox": {
                        "x0": 395.5481872558594,
                        "y0": 286.1600036621094,
                        "x1": 462.006103515625,
                        "y1": 295.0400085449219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "noise or failures",
                    "bbox": {
                        "x0": 399.8020935058594,
                        "y0": 296.4800109863281,
                        "x1": 457.7618408203125,
                        "y1": 305.3600158691406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Usage Not really used for",
                    "bbox": {
                        "x0": 130.5601043701172,
                        "y0": 314.7200012207031,
                        "x1": 274.4534912109375,
                        "y1": 323.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "combining modalities",
                    "bbox": {
                        "x0": 201.48980712890625,
                        "y0": 325.0400085449219,
                        "x1": 279.7015075683594,
                        "y1": 333.9200134277344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Used for fusion of",
                    "bbox": {
                        "x0": 304.2143859863281,
                        "y0": 314.7200012207031,
                        "x1": 369.9263916015625,
                        "y1": 323.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "particular modes",
                    "bbox": {
                        "x0": 306.9764099121094,
                        "y0": 325.0400085449219,
                        "x1": 367.18280029296875,
                        "y1": 333.9200134277344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Most widely used",
                    "bbox": {
                        "x0": 396.79620361328125,
                        "y0": 314.7200012207031,
                        "x1": 460.7410888671875,
                        "y1": 323.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "type of fusion",
                    "bbox": {
                        "x0": 403.79449462890625,
                        "y0": 325.0400085449219,
                        "x1": 453.7445068359375,
                        "y1": 333.9200134277344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Application",
                    "bbox": {
                        "x0": 130.5601043701172,
                        "y0": 343.2799987792969,
                        "x1": 175.5284423828125,
                        "y1": 352.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "examples",
                    "bbox": {
                        "x0": 130.5601043701172,
                        "y0": 353.6000061035156,
                        "x1": 166.0179443359375,
                        "y1": 362.4800109863281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Fusion of two video",
                    "bbox": {
                        "x0": 204.4824981689453,
                        "y0": 343.2799987792969,
                        "x1": 276.69464111328125,
                        "y1": 352.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "streams",
                    "bbox": {
                        "x0": 226.86380004882812,
                        "y0": 353.6000061035156,
                        "x1": 254.31187438964844,
                        "y1": 362.4800109863281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "speech recognition",
                    "bbox": {
                        "x0": 303.2278137207031,
                        "y0": 343.2799987792969,
                        "x1": 370.9200439453125,
                        "y1": 352.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "from voice and lips",
                    "bbox": {
                        "x0": 302.22149658203125,
                        "y0": 353.6000061035156,
                        "x1": 371.9294738769531,
                        "y1": 362.4800109863281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Pen/speech",
                    "bbox": {
                        "x0": 408.5714111328125,
                        "y0": 343.2799987792969,
                        "x1": 448.97540283203125,
                        "y1": 352.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interaction",
                    "bbox": {
                        "x0": 409.5534973144531,
                        "y0": 353.6000061035156,
                        "x1": 448.00390625,
                        "y1": 362.4800109863281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Typical architectures for decision-level fusion are frame-based fusion, unification-",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 383.6000061035156,
                        "x1": 470.8221435546875,
                        "y1": 393.44000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "based fusion and hybrid symbolic/statistical fusion.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 395.1199951171875,
                        "x1": 330.3910217285156,
                        "y1": 404.9599914550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Frame-based fusion [70] uses data structures called frames or features for meaning",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 406.8800048828125,
                        "x1": 470.7395324707031,
                        "y1": 417.2021789550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "representation of data coming from various sources or modalities. These structures",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 418.3999938964844,
                        "x1": 470.802490234375,
                        "y1": 428.239990234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "represent objects as attribute-value pairs.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 429.91998291015625,
                        "x1": 299.88751220703125,
                        "y1": 439.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Unification-based fusion [27] is based on recursively merging attribute-value",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 441.44000244140625,
                        "x1": 470.81402587890625,
                        "y1": 451.7621765136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "structures to obtain a logical whole meaning representation.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 452.9599914550781,
                        "x1": 375.0495300292969,
                        "y1": 462.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Symbolic/statistical fusion [74] is an evolution of standard symbolic unification-",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 464.47998046875,
                        "x1": 470.8221435546875,
                        "y1": 474.8021545410156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "based approaches, which adds statistical processing techniques to the fusion",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 476.0,
                        "x1": 470.7137756347656,
                        "y1": 485.8399963378906
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "techniques described above. These kinds of “hybrid” fusion techniques have been",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 487.5199890136719,
                        "x1": 470.71392822265625,
                        "y1": 497.3599853515625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "demonstrated to achieve robust and reliable results. An example of a symbolic-",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 499.0400085449219,
                        "x1": 470.8221435546875,
                        "y1": 508.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "statistical hybrid fusion technique is the Member-Team-Committee (MTC)",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 510.79998779296875,
                        "x1": 470.8173828125,
                        "y1": 520.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "architecture used in Quickset [75].",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 522.3200073242188,
                        "x1": 274.35382080078125,
                        "y1": 532.1600341796875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "3.4 Fission of Output Modalities",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 555.6799926757812,
                        "x1": 266.9245300292969,
                        "y1": 565.52001953125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "When multiple output modalities such as text-to-speech synthesis, audio cues, visual",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 578.239990234375,
                        "x1": 470.7929992675781,
                        "y1": 588.0800170898438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "cues, haptic feedback or animated agents are available, output selection becomes a",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 590.0,
                        "x1": 470.73974609375,
                        "y1": 599.8400268554688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "delicate task to adapt to a context of use (e.g. car, home, work), type of task (e.g.,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 601.52001953125,
                        "x1": 470.828125,
                        "y1": 611.3600463867188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "information search, entertainment) or type of user (e.g. visually impaired, elderly).",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 613.0399780273438,
                        "x1": 455.1759033203125,
                        "y1": 622.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Fission techniques [23] allow a multimodal application to generate a given message in",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 624.5599975585938,
                        "x1": 470.75146484375,
                        "y1": 634.4000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "an adequate form according to the context and user profiles. Technically speaking,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 636.0800170898438,
                        "x1": 470.7734680175781,
                        "y1": 645.9200439453125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "fission consists of three tasks:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 647.5999755859375,
                        "x1": 244.3772430419922,
                        "y1": 657.4400024414062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Message construction, where the information to be transmitted to the user is",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 659.1199951171875,
                        "x1": 470.7395935058594,
                        "y1": 669.442138671875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "created; approaches for content selection and structuring revolve mainly around",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 670.6400146484375,
                        "x1": 470.7287902832031,
                        "y1": 680.4800415039062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "either schema-based approaches or plan-based approaches [40, 43].",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 682.1599731445312,
                        "x1": 405.9847106933594,
                        "y1": 692.0
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 12,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "12 Bruno Dumas1, Denis Lalanne1, Sharon Oviatt2",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 121.99996948242188,
                        "x1": 333.7164001464844,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Output channel selection, where interfaces are selected according to context and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.1199951171875,
                        "x1": 470.6539611816406,
                        "y1": 159.44215393066406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "user profile in order to convey all data effectively in a given situation.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 160.6400146484375,
                        "x1": 470.7940368652344,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Characteristics such as available output modalities, information to be presented,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 172.15997314453125,
                        "x1": 470.784423828125,
                        "y1": 181.99998474121094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "communicative goals of the presenter, user characteristics and task to be performed",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 183.91998291015625,
                        "x1": 470.6645812988281,
                        "y1": 193.75999450683594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "are forms of knowledge that can be used for output channel selection [2, 3].",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 195.44000244140625,
                        "x1": 438.7630310058594,
                        "y1": 205.28001403808594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Construction of a coherent and synchronized result: when multiple output channels",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 206.96002197265625,
                        "x1": 470.7294921875,
                        "y1": 217.2821807861328
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "are used, layout and temporal coordination are to be taken into account. Moreover,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 218.47998046875,
                        "x1": 470.7138671875,
                        "y1": 228.3199920654297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "some systems will produce multimodal and cross-modal referring expressions,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 230.0,
                        "x1": 470.7925720214844,
                        "y1": 239.8400115966797
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "which will also have to be coordinated.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 241.52001953125,
                        "x1": 293.2191467285156,
                        "y1": 251.3600311279297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "3.5 Dialogue Management & Time-Sensitive Architectures",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 281.3599853515625,
                        "x1": 378.601318359375,
                        "y1": 291.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The time constraint is highly important in multimodal systems and all the modalities",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 307.03997802734375,
                        "x1": 470.74542236328125,
                        "y1": 316.8799743652344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "should be properly time-stamped and synchronized. Time-sensitive architectures need",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 318.55999755859375,
                        "x1": 470.8076171875,
                        "y1": 328.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "to establish temporal thresholds for time-stamping start and end of each input signal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 330.0799865722656,
                        "x1": 470.8164978027344,
                        "y1": 339.91998291015625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "piece, so that two commands sequences can be identified. Indeed, when two",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 341.8399963378906,
                        "x1": 470.6600036621094,
                        "y1": 351.67999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "commands are performed in parallel, in a synergistic way, it is important to know in",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 353.3599853515625,
                        "x1": 470.8102111816406,
                        "y1": 363.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "which order the commands have been entered because the interpretation will vary",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 364.8800048828125,
                        "x1": 470.7951965332031,
                        "y1": 374.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "accordingly. For instance, in the following application, in which voice and gestures",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 376.3999938964844,
                        "x1": 470.6749267578125,
                        "y1": 386.239990234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "are used simultaneously to control a music player, depending on the order in which",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 387.91998291015625,
                        "x1": 470.6797790527344,
                        "y1": 397.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modalities are presented the interpretation varies:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 399.44000244140625,
                        "x1": 322.36846923828125,
                        "y1": 409.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• <pointing> “Play next track”: will result in playing the track following the one",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 410.9599914550781,
                        "x1": 470.6937561035156,
                        "y1": 421.28216552734375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "selected with a gesture;",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 422.47998046875,
                        "x1": 229.88003540039062,
                        "y1": 432.3199768066406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• “Play” <pointing> “next track”: will result in first playing the manually selected",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 434.0,
                        "x1": 470.7107238769531,
                        "y1": 444.3221740722656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "track and then passing to the following at the time “next is pronounced”;",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 445.760009765625,
                        "x1": 426.7753601074219,
                        "y1": 455.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• “Play next track” <pointing>: In this case, the system should interpret the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 457.2799987792969,
                        "x1": 470.74298095703125,
                        "y1": 467.6021728515625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "commands as being redundant.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 468.79998779296875,
                        "x1": 260.15771484375,
                        "y1": 478.6399841308594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The dialog management system and synchronization mechanism should consider",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 491.8399963378906,
                        "x1": 470.6994323730469,
                        "y1": 501.67999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multiple potential causes of lag:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 503.3599853515625,
                        "x1": 252.68460083007812,
                        "y1": 513.2000122070312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• delay due to technology (e.g. speech recognition);",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 513.4925537109375,
                        "x1": 333.9289245605469,
                        "y1": 525.2021484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• delay due to multimodal system architecture;",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 529.092529296875,
                        "x1": 314.221923828125,
                        "y1": 540.8021240234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• user differences in habitual multimodal integration pattern [51][55].",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 544.4525146484375,
                        "x1": 405.58282470703125,
                        "y1": 556.162109375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "For this reason, multi-agent architectures (or similar architectures such as",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 572.9599609375,
                        "x1": 470.77398681640625,
                        "y1": 582.7999877929688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "components-based systems) are advantageous for distributing processing and for",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 584.47998046875,
                        "x1": 470.8375549316406,
                        "y1": 594.3200073242188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "coordinating many system components (e.g., speech recognition, pen recognition,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 596.0,
                        "x1": 470.6993713378906,
                        "y1": 605.8400268554688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "natural language processing, graphic display, TTS output, application database).",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 607.760009765625,
                        "x1": 446.0254821777344,
                        "y1": 617.6000366210938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Bui [13] considers four different approaches to dialog management:",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 630.7999877929688,
                        "x1": 407.8419189453125,
                        "y1": 640.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Finite-state and frame-based approaches: in this kind of dialog management",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 642.3200073242188,
                        "x1": 470.762451171875,
                        "y1": 652.6421508789062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "approach, the dialog structure is represented in the form of a state machine. Frame-",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 653.8399658203125,
                        "x1": 470.8221435546875,
                        "y1": 663.6799926757812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "based models are an extension of finite-state models, using a slot-filling strategy in",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 665.3599853515625,
                        "x1": 470.7715759277344,
                        "y1": 675.2000122070312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "which a number of predefined information sources are to be gathered [16].",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 676.8800048828125,
                        "x1": 434.58331298828125,
                        "y1": 686.7200317382812
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 13,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "Multimodal Interfaces: A Survey of Principles, Models and Frameworks 13",
                    "bbox": {
                        "x0": 180.66659545898438,
                        "y0": 121.99996948242188,
                        "x1": 470.8323669433594,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Information state-based and probabilistic approaches: these approaches try to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.1199951171875,
                        "x1": 470.7851867675781,
                        "y1": 159.44215393066406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "describe human-machine dialog following information states, consisting of five",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 160.6400146484375,
                        "x1": 470.70489501953125,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "main components: informational components, formal representations of those",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 172.15997314453125,
                        "x1": 470.7040100097656,
                        "y1": 181.99998474121094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "components, a set of dialog moves, a set of update rules and an update strategy",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 183.91998291015625,
                        "x1": 470.7901916503906,
                        "y1": 193.75999450683594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "[68].",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 195.44000244140625,
                        "x1": 155.51101684570312,
                        "y1": 205.28001403808594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Plan-based approaches: the plan-based approaches are based on the plan-based",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 206.96002197265625,
                        "x1": 470.8028259277344,
                        "y1": 217.2821807861328
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "theories of communicative action and dialog [16]. These theories claim that the",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 218.47998046875,
                        "x1": 470.7823791503906,
                        "y1": 228.3199920654297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "speaker’s speech act is part of a plan and that it is the listener’s job to identify and",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 230.0,
                        "x1": 470.6915588378906,
                        "y1": 239.8400115966797
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "respond appropriately to this plan [15].",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 241.52001953125,
                        "x1": 292.42510986328125,
                        "y1": 251.3600311279297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Collaborative agents-based approaches: these approaches view dialog as a",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 253.03997802734375,
                        "x1": 470.7578125,
                        "y1": 263.3621520996094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "collaborative process between intelligent agents. The agents work together to",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 264.55999755859375,
                        "x1": 470.7571105957031,
                        "y1": 274.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "obtain a mutual understanding of the dialog. This induces discourse phenomena",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 276.08001708984375,
                        "x1": 470.73358154296875,
                        "y1": 285.9200134277344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "such as clarifications and confirmations [48].",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 287.8399658203125,
                        "x1": 316.8587341308594,
                        "y1": 297.6799621582031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "3.6 Machine Learning for Multimodal Interaction",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 321.20001220703125,
                        "x1": 342.6517028808594,
                        "y1": 331.0400085449219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Machine learning techniques play an important role in multimodal interfaces [26], and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 343.760009765625,
                        "x1": 470.8062744140625,
                        "y1": 353.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "most certainly will continue to extend this role. Indeed, many parts of multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 355.2799987792969,
                        "x1": 470.6502380371094,
                        "y1": 365.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "systems are likely to receive support from machine learning. Modality recognizers",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 367.0400085449219,
                        "x1": 470.6797180175781,
                        "y1": 376.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "already make extensive use of machine learning: speech recognition, face detection,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 378.55999755859375,
                        "x1": 470.6885681152344,
                        "y1": 388.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "face recognition, facial expression analysis, gesture recognition or eye tracking are",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 390.0799865722656,
                        "x1": 470.6599426269531,
                        "y1": 399.91998291015625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "examples of different domains of interest both for multimodal interaction and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 401.6000061035156,
                        "x1": 470.66986083984375,
                        "y1": 411.44000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "machine learning.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 413.1199951171875,
                        "x1": 196.62855529785156,
                        "y1": 422.9599914550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Aside from modality handling, machine learning has been applied for fusion of",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 424.6399841308594,
                        "x1": 470.6646423339844,
                        "y1": 434.47998046875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "input recognizers’ data, mainly at the feature level. Fewer works have been achieved",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 436.1600036621094,
                        "x1": 470.66015625,
                        "y1": 446.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "on decision level fusion with assistance from machine learning. An example of such",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 447.67999267578125,
                        "x1": 470.6601257324219,
                        "y1": 457.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "work is Pan et al. [55], who proposed context-dependent versions of Bayesian",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 459.1999816894531,
                        "x1": 470.7735900878906,
                        "y1": 469.03997802734375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "inference method for multisensory data fusion. Nonetheless, Jaimes & Sebe [26]",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 470.9599914550781,
                        "x1": 470.8368225097656,
                        "y1": 480.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "reckon that “further research is still required to investigate fusion models able to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 482.47998046875,
                        "x1": 470.7594299316406,
                        "y1": 492.3199768066406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "efficiently use the complementary cues provided by multiple modalities”. User, task",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 494.0,
                        "x1": 470.7859802246094,
                        "y1": 503.8399963378906
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and context modeling also can benefit from machine learning techniques. Novel",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 505.52001953125,
                        "x1": 470.7388000488281,
                        "y1": 515.3600463867188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "research fields related to machine learning, such as social signal processing [64], will",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 517.0400390625,
                        "x1": 470.8358459472656,
                        "y1": 526.8800659179688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "help building a refined representation of the user in her collaborative context.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 528.5599975585938,
                        "x1": 470.67962646484375,
                        "y1": 538.4000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Adaptability can then be addressed with the help of machine learning, by watching",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 540.0799560546875,
                        "x1": 470.6501770019531,
                        "y1": 549.9199829101562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "the users’ behavior in the sensed context [21].",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 551.5999755859375,
                        "x1": 308.8338317871094,
                        "y1": 561.4400024414062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "As Jaimes & Sebe [26] highlight, currently “most researchers process each",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 563.1199951171875,
                        "x1": 470.7554626464844,
                        "y1": 572.9600219726562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "channel (visual, audio) independently, and multimodal fusion is still in its infancy”.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 574.8800048828125,
                        "x1": 470.8495178222656,
                        "y1": 584.7200317382812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Thus, multimodal interaction researchers have work to achieve in order to attain",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 586.4000244140625,
                        "x1": 470.7371520996094,
                        "y1": 596.2400512695312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "efficient multimodal fusion, with careful consideration of the different available",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 597.9199829101562,
                        "x1": 470.6993408203125,
                        "y1": 607.760009765625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modalities and the way modalities interlock. Machine learning will be of interest in",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 609.4400024414062,
                        "x1": 470.6501770019531,
                        "y1": 619.280029296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "order to attain such a goal. Besides multimodal fusion, machine learning will help",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 620.9599609375,
                        "x1": 470.7296447753906,
                        "y1": 630.7999877929688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal applications take into account the affective aspect of communication –",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 632.47998046875,
                        "x1": 470.78582763671875,
                        "y1": 642.3200073242188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "emotions based on their physiological manifestations [41], such as facial expressions,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 644.0,
                        "x1": 470.8121337890625,
                        "y1": 653.8400268554688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "gestures, postures, tone of voice, respiration, etc.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 655.52001953125,
                        "x1": 320.1393737792969,
                        "y1": 665.3600463867188
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 14,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "14 Bruno Dumas1, Denis Lalanne1, Sharon Oviatt2",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 121.99996948242188,
                        "x1": 333.7164001464844,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "4 Modeling Languages and Frameworks",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.17999267578125,
                        "x1": 337.7160949707031,
                        "y1": 161.17999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "There have been several attempts to model and formalize multimodal interaction. This",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 176.96002197265625,
                        "x1": 470.8216552734375,
                        "y1": 186.80003356933594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "section presents several different levels of modeling. The first part introduces two",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 188.47998046875,
                        "x1": 470.72021484375,
                        "y1": 198.3199920654297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "abstract models designed to help developers evaluate the different types of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 200.0,
                        "x1": 470.80523681640625,
                        "y1": 209.8400115966797
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal interaction, viewed first from the machine side, then from the user side.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 211.760009765625,
                        "x1": 470.7986145019531,
                        "y1": 221.6000213623047
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The second part lists a number of languages used for multimodal recognizer output",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 223.27996826171875,
                        "x1": 470.6896057128906,
                        "y1": 233.11997985839844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and multimodal synthesizer input representations, and modeling languages used to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 234.79998779296875,
                        "x1": 470.8082580566406,
                        "y1": 244.63999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "configure multimodal systems. The final part displays different programming",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 246.32000732421875,
                        "x1": 470.78326416015625,
                        "y1": 256.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "frameworks for rapid creation of multimodal interfaces.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 257.8399658203125,
                        "x1": 347.9884033203125,
                        "y1": 267.6799621582031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "4.1 Multimodal Interaction Modeling",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 291.20001220703125,
                        "x1": 288.8511962890625,
                        "y1": 301.0400085449219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Modeling multimodal interaction is no simple task, due to the multiple input and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 314.0,
                        "x1": 470.6737365722656,
                        "y1": 323.8399963378906
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "output channels and modes, and the combination of possibilities between data coming",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 325.5199890136719,
                        "x1": 470.6895446777344,
                        "y1": 335.3599853515625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "from different sources, not to mention output modality selection based on context and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 337.0400085449219,
                        "x1": 470.6305847167969,
                        "y1": 346.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "user profile.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 348.55999755859375,
                        "x1": 173.29547119140625,
                        "y1": 358.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The shape taken by formal modeling of multimodal interaction depends on the",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 360.0799865722656,
                        "x1": 470.75,
                        "y1": 369.91998291015625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "level of abstraction considered. At lower levels of abstraction, formal modeling would",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 371.6000061035156,
                        "x1": 470.6501770019531,
                        "y1": 381.44000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "focus on tools used for modality recognition and synthesis. At higher levels of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 383.1199951171875,
                        "x1": 470.6797180175781,
                        "y1": 392.9599914550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "abstraction, multimodal interaction modeling would focus more on modality",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 394.8800048828125,
                        "x1": 470.7082214355469,
                        "y1": 404.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "combination and synchronization.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 406.3999938964844,
                        "x1": 260.7435302734375,
                        "y1": 416.239990234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Formal modeling can also focus on the “pure” technical part as well as on the user-",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 417.91998291015625,
                        "x1": 470.8221435546875,
                        "y1": 427.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "machine interaction. Two formal models exist for modality combination description:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 429.44000244140625,
                        "x1": 463.6539001464844,
                        "y1": 439.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• The CASE model [46], focusing on modality combination possibilities at the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 440.9599914550781,
                        "x1": 470.73370361328125,
                        "y1": 451.28216552734375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "fusion engine level;",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 452.47998046875,
                        "x1": 215.1889190673828,
                        "y1": 462.3199768066406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• the CARE model [18], giving attention to modality combination possibilities at the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 464.0,
                        "x1": 470.727294921875,
                        "y1": 474.3221740722656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "user level.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 475.5199890136719,
                        "x1": 177.4230194091797,
                        "y1": 485.3599853515625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The CASE model introduces four properties: Concurrent – Alternate – Synergistic",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 487.2799987792969,
                        "x1": 470.7994384765625,
                        "y1": 497.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "– Exclusive (figure 4). Each of those four properties describes a different way to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 498.79998779296875,
                        "x1": 470.7447204589844,
                        "y1": 508.6399841308594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "combine modalities at the integration engine level, depending on two factors:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 510.32000732421875,
                        "x1": 470.74871826171875,
                        "y1": 520.1600341796875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "combined or independent fusion of modalities, and sequential or synergistic use of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 521.8399658203125,
                        "x1": 470.71923828125,
                        "y1": 531.6799926757812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modalities on the other hand. “Fusion of modalities” considers if different modalities",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 533.3599853515625,
                        "x1": 470.70904541015625,
                        "y1": 543.2000122070312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "are combined or managed independently, whereas “Use of modalities” observes the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 544.8800048828125,
                        "x1": 470.65997314453125,
                        "y1": 554.7200317382812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "way modalities are activated: either one at a time, or in a synergistic manner.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 556.4000244140625,
                        "x1": 432.2900390625,
                        "y1": 566.2400512695312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The CARE model is more focused on the user-machine interaction level. This",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 567.9199829101562,
                        "x1": 470.78680419921875,
                        "y1": 577.760009765625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "model also introduces four properties, which are Complementarity – Assignment –",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 579.4400024414062,
                        "x1": 470.78582763671875,
                        "y1": 589.280029296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Redundancy – Equivalence. Complementarity is to be used when multiple",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 591.2000122070312,
                        "x1": 470.8003234863281,
                        "y1": 601.0400390625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "complementary modalities are necessary to grasp the desired meaning (e.g. “put that",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 602.719970703125,
                        "x1": 470.8246154785156,
                        "y1": 612.5599975585938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "there” [9] would need both pointing gestures and voice in order to be resolved).",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 614.239990234375,
                        "x1": 470.7491455078125,
                        "y1": 624.0800170898438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Assignment indicates that only one modality can lead to the desired meaning (e.g. the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 625.760009765625,
                        "x1": 470.8157958984375,
                        "y1": 635.6000366210938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "steering wheel of a car is the only way to direct the car). Redundancy implies multiple",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 637.280029296875,
                        "x1": 470.74853515625,
                        "y1": 647.1200561523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modalities which, even if used simultaneously, can be used individually to lead to the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 648.7999877929688,
                        "x1": 470.80145263671875,
                        "y1": 658.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "desired meaning (e.g. user utters a “play” speech command and pushes a button",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 660.3200073242188,
                        "x1": 470.7412414550781,
                        "y1": 670.1600341796875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "labeled “play”, but only one “play” command would be taken into account). Finally,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 671.8399658203125,
                        "x1": 470.7781066894531,
                        "y1": 681.6799926757812
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 15,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "Multimodal Interfaces: A Survey of Principles, Models and Frameworks 15",
                    "bbox": {
                        "x0": 180.66659545898438,
                        "y0": 121.99996948242188,
                        "x1": 470.8323669433594,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Equivalence entails multiple modalities that can all lead to the desired meaning, but",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.1199951171875,
                        "x1": 470.77691650390625,
                        "y1": 158.9600067138672
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "only one would be used at a time (e.g. speech or keyboard can be used to write a text).",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 160.6400146484375,
                        "x1": 470.10760498046875,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Fig. 4. The CASE model.",
                    "bbox": {
                        "x0": 253.78419494628906,
                        "y0": 323.6000061035156,
                        "x1": 353.4544982910156,
                        "y1": 333.44000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "4.2 Multimodal Interaction Modeling Languages",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 356.9599914550781,
                        "x1": 337.4364929199219,
                        "y1": 366.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Interesting attempts at creating a full-fledged language for description of user-",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 379.5199890136719,
                        "x1": 470.8221435546875,
                        "y1": 389.3599853515625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "machine multimodal interaction have arisen in the past few years. Most of the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 391.2799987792969,
                        "x1": 470.8087158203125,
                        "y1": 401.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "approaches presented below revolve around the concept of a “multimodal web”,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 402.79998779296875,
                        "x1": 470.78790283203125,
                        "y1": 412.6399841308594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "enforced by the World Wide Web Consortium (W3C) Multimodal Interaction",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 414.32000732421875,
                        "x1": 470.7288818359375,
                        "y1": 424.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Activity and its proposed multimodal architecture [71]. This theoretical framework",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 425.8399963378906,
                        "x1": 470.7743835449219,
                        "y1": 435.67999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "describes major components involved in multimodal interaction, as well as potential",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 437.3599853515625,
                        "x1": 470.6502380371094,
                        "y1": 447.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "or existent markup languages used to relate those different components. Many",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 448.8800048828125,
                        "x1": 470.66986083984375,
                        "y1": 458.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "elements described in this framework are of practical interest for multimodal HCI",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 460.3999938964844,
                        "x1": 470.8363952636719,
                        "y1": 470.239990234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "practitioners, such as the W3C EMMA markup language, or modality-focused",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 471.91998291015625,
                        "x1": 470.8023986816406,
                        "y1": 481.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "languages such as VoiceXML or InkML. The work of the W3C inspired Katsurada et",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 483.44000244140625,
                        "x1": 470.7290344238281,
                        "y1": 493.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "al. for their work on the XISL XML language [28]. XISL focuses on synchronization",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 495.1999816894531,
                        "x1": 470.7861022949219,
                        "y1": 505.03997802734375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "of multimodal input and output, as well as dialog flow and transition. Another",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 506.719970703125,
                        "x1": 470.6895751953125,
                        "y1": 516.5599975585938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "approach of the problem is the one of Araki et al. [4], who propose MIML",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 518.239990234375,
                        "x1": 470.7752380371094,
                        "y1": 528.0800170898438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "(Multimodal Interaction Markup Language). One of the key characteristics of this",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 529.760009765625,
                        "x1": 470.7967834472656,
                        "y1": 539.6000366210938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "language is its three-layered description of interaction, focusing on interaction, tasks",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 541.280029296875,
                        "x1": 470.7181701660156,
                        "y1": 551.1200561523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and platform. Finally, Stanciulescu et al. [64] followed a transformational approach",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 552.7999877929688,
                        "x1": 470.7657775878906,
                        "y1": 562.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "for developing multimodal web user interfaces based on UsiXML, also in the steps of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 564.3200073242188,
                        "x1": 470.75274658203125,
                        "y1": 574.1600341796875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "the W3C. Four steps are achieved to go from a generic model to the final user",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 575.8399658203125,
                        "x1": 470.7288818359375,
                        "y1": 585.6799926757812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interface. Thus, one of the main features of their work is a strong independence to the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 587.5999755859375,
                        "x1": 470.630615234375,
                        "y1": 597.4400024414062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "actual input and output available channels.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 599.1199951171875,
                        "x1": 295.4898681640625,
                        "y1": 608.9600219726562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Sire and Chatty describe in [63] what one should expect from a multimodal user",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 622.1599731445312,
                        "x1": 470.74468994140625,
                        "y1": 632.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interfaces programming language. From their proposal, the following requirements",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 633.6799926757812,
                        "x1": 470.6600036621094,
                        "y1": 643.52001953125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "for a multimodal description language have been derived.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 645.2000122070312,
                        "x1": 355.3846130371094,
                        "y1": 655.0400390625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Such a language should be modality agnostic, as research in input and output",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 656.719970703125,
                        "x1": 470.822021484375,
                        "y1": 667.0421142578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modalities continues to evolve today.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 668.239990234375,
                        "x1": 285.4170227050781,
                        "y1": 678.0800170898438
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [
                {
                    "type": "figure",
                    "bbox": {
                        "x0": 216.0,
                        "y0": 182.17999267578125,
                        "x1": 391.44000244140625,
                        "y1": 321.8599853515625
                    },
                    "vlm_description": "The image is a matrix that categorizes the use and fusion of modalities. It consists of a two-by-two grid, organized by two dimensions:\n\n1. **Use of Modalities** (across the top):\n   - **Sequential**\n   - **Parallel**\n\n2. **Fusion of Modalities** (along the side):\n   - **Independent**\n   - **Combined**\n\nEach quadrant represents a different combination:\n\n- **Independent & Sequential**: Labeled as \"ALTERNATE\"\n- **Independent & Parallel**: Labeled as \"EXCLUSIVE\"\n- **Combined & Sequential**: Labeled as \"SYNERGISTIC\"\n- **Combined & Parallel**: Labeled as \"CONCURRENT\"\n\nThis categorization likely refers to how different modalities can be used or fused in various contexts, possibly in learning, technology, or communication.",
                    "vlm_structured_data": null,
                    "associated_text_indices": null
                }
            ],
            "image_path": null
        },
        {
            "page_number": 16,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "16 Bruno Dumas1, Denis Lalanne1, Sharon Oviatt2",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 121.99996948242188,
                        "x1": 333.7164001464844,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• A binding mechanism to link the definition of the user interface composition with",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.1199951171875,
                        "x1": 470.6964416503906,
                        "y1": 159.44215393066406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "its runtime realization should be provided.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 160.6400146484375,
                        "x1": 306.865234375,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Explicit control structures should be present, such as conditional clauses and loops.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 172.15997314453125,
                        "x1": 470.3522644042969,
                        "y1": 182.4821319580078
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Extensible event definition mechanisms are also needed for communication",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 183.91998291015625,
                        "x1": 470.73297119140625,
                        "y1": 194.2421417236328
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "between user interface objects and the interaction model.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 195.44000244140625,
                        "x1": 363.940185546875,
                        "y1": 205.28001403808594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Data Modeling should be carefully planned, as application data tends to be",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 206.96002197265625,
                        "x1": 470.8045654296875,
                        "y1": 217.2821807861328
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "distributed in multiple places.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 218.47998046875,
                        "x1": 255.14918518066406,
                        "y1": 228.3199920654297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "• Finally, a major requirement for a multimodal integration description language is",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 230.0,
                        "x1": 470.6449890136719,
                        "y1": 240.32215881347656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "the definition of reusable components.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 241.52001953125,
                        "x1": 290.4956970214844,
                        "y1": 251.3600311279297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "“Modality agnostic” is the most debatable of those requirements, as one could",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 264.55999755859375,
                        "x1": 470.7237243652344,
                        "y1": 274.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "argue that such a requirement will never be achievable, as every modality has its own",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 276.08001708984375,
                        "x1": 470.6311950683594,
                        "y1": 285.9200134277344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "particularities. Our interpretation of this requirement is the following: “modality",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 287.8399658203125,
                        "x1": 470.62066650390625,
                        "y1": 297.6799621582031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "agnostic” means that the language should not be specific for each individual modality,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 299.3599853515625,
                        "x1": 470.7485046386719,
                        "y1": 309.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "as modalities are all different; the language should be flexible enough (or canonic",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 310.8800048828125,
                        "x1": 470.6502380371094,
                        "y1": 320.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "enough) to be adapted to a new and different modality. Hence, if a scripting or",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 322.4000244140625,
                        "x1": 470.768310546875,
                        "y1": 332.2400207519531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "programming language can be in principle modality agnostic, such cannot be said of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 333.91998291015625,
                        "x1": 470.7486877441406,
                        "y1": 343.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "the fusion engine that needs to take into account the specificities of each modality to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 345.44000244140625,
                        "x1": 470.64923095703125,
                        "y1": 355.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "fuse data or features correctly.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 356.9599914550781,
                        "x1": 246.2787322998047,
                        "y1": 366.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "A last point that stems from these six guidelines is readability: a language for",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 380.0,
                        "x1": 470.82928466796875,
                        "y1": 389.8399963378906
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "description of multimodal interaction should be readable, as much in regard to the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 391.760009765625,
                        "x1": 470.82049560546875,
                        "y1": 401.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "machine as to humans.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 403.2799987792969,
                        "x1": 216.05027770996094,
                        "y1": 413.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Formal languages for description of multimodal description can be approached",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 414.79998779296875,
                        "x1": 470.6943054199219,
                        "y1": 424.6399841308594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "from two different directions: either from expressiveness, or from usability.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 426.32000732421875,
                        "x1": 470.6796875,
                        "y1": 436.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Expressiveness covers technical features such as extensibility, completeness,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 437.8399963378906,
                        "x1": 470.803955078125,
                        "y1": 447.67999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "reusability, or temporal aspects considerations; usability covers more human features",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 449.3599853515625,
                        "x1": 470.6600341796875,
                        "y1": 459.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "such as programmability or readability. Any formal language will have to find its",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 460.8800048828125,
                        "x1": 470.6993713378906,
                        "y1": 470.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "place between those two general requirements; some languages will tend more toward",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 472.3999938964844,
                        "x1": 470.7929382324219,
                        "y1": 482.239990234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "expressiveness or usability. An interesting approach is to seek balance between",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 484.1600036621094,
                        "x1": 470.6896057128906,
                        "y1": 494.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "usability and expressiveness: that is, a language able to configure a multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 495.67999267578125,
                        "x1": 470.6600341796875,
                        "y1": 505.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "system, with high level modeling, and readable enough to be used as a learning tool,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 507.199951171875,
                        "x1": 470.83807373046875,
                        "y1": 517.0399780273438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "or even a communication tool.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 518.719970703125,
                        "x1": 246.8593292236328,
                        "y1": 528.5599975585938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "4.3 Programming Frameworks",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 552.0799560546875,
                        "x1": 261.8901062011719,
                        "y1": 561.9199829101562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Further to multimodal interface creation, a number of tools have become available in",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 574.8800048828125,
                        "x1": 470.67974853515625,
                        "y1": 584.7200317382812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "recent years. Krahnstoever et al. [32] proposed a framework using speech and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 586.4000244140625,
                        "x1": 470.7553405761719,
                        "y1": 596.2400512695312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "gestures to create a natural interface. The output of their framework was to be used on",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 597.9199829101562,
                        "x1": 470.6418762207031,
                        "y1": 607.760009765625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "large screen displays enabling multi-user interaction. Fusion was done using a",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 609.4400024414062,
                        "x1": 470.7752685546875,
                        "y1": 619.280029296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "unification-based method. Cohen et al. [17] worked on Quickset, a speech/pen",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 620.9599609375,
                        "x1": 470.7981872558594,
                        "y1": 630.7999877929688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal interface, based on Open Agent Architecture, which served as a test bed",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 632.47998046875,
                        "x1": 470.709228515625,
                        "y1": 642.3200073242188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "for unification-based and hybrid fusion methods. Bourguet [11] endeavored in the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 644.0,
                        "x1": 470.78533935546875,
                        "y1": 653.8400268554688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "creation of a multimodal toolkit in which multimodal scenarios could be modelled",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 655.52001953125,
                        "x1": 470.7630920410156,
                        "y1": 665.3600463867188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "using finite state machines. This multimodal toolkit is composed of two components,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 667.280029296875,
                        "x1": 470.7093505859375,
                        "y1": 677.1200561523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "a graphical user interface named IMBuilder which interfaces the multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 678.7999877929688,
                        "x1": 470.7387390136719,
                        "y1": 688.6400146484375
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 17,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "Multimodal Interfaces: A Survey of Principles, Models and Frameworks 17",
                    "bbox": {
                        "x0": 180.66659545898438,
                        "y0": 121.99996948242188,
                        "x1": 470.8323669433594,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "framework itself, named MEngine. Multimodal interaction models created with",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.1199951171875,
                        "x1": 470.7969055175781,
                        "y1": 158.9600067138672
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "IMBuilder are saved as a XML file. Flippo et al. [22] also worked on the design of a",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 160.6400146484375,
                        "x1": 470.7959289550781,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal framework, geared toward direct integration into a multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 172.15997314453125,
                        "x1": 470.69940185546875,
                        "y1": 181.99998474121094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "application. One of the most interesting aspects of their work is the use of a parallel",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 183.91998291015625,
                        "x1": 470.81195068359375,
                        "y1": 193.75999450683594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "application-independent fusion technique. The general framework architecture is",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 195.44000244140625,
                        "x1": 470.7193298339844,
                        "y1": 205.28001403808594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "based on agents, while the fusion technique itself uses frames. Configuration of the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 206.96002197265625,
                        "x1": 470.65997314453125,
                        "y1": 216.80003356933594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "fusion is done via an XML file, specifying for each frame a number of slots to be",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 218.47998046875,
                        "x1": 470.78192138671875,
                        "y1": 228.3199920654297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "filled and direct link to actual resolver implementations. Lastly, Bouchet et al. [10]",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 230.0,
                        "x1": 470.8368225097656,
                        "y1": 239.8400115966797
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "proposed a component-based approach called ICARE thoroughly based on the CARE",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 241.52001953125,
                        "x1": 470.73016357421875,
                        "y1": 251.3600311279297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "[18] design space. These components cover elementary tasks, modality-dependent",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 253.03997802734375,
                        "x1": 470.83905029296875,
                        "y1": 262.8799743652344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "tasks or generic tasks like fusion. Finally, communication between components is",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 264.55999755859375,
                        "x1": 470.7191467285156,
                        "y1": 274.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "based on events. The components-based approach of ICARE has provided inspiration",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 276.08001708984375,
                        "x1": 470.7713623046875,
                        "y1": 285.9200134277344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "for a comprehensive open-source toolkit called OpenInterface [61]. OpenInterface",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 287.8399658203125,
                        "x1": 470.8037109375,
                        "y1": 297.6799621582031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "components are configured via CIDL XML files, and a graphical editor.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 299.3599853515625,
                        "x1": 413.1836853027344,
                        "y1": 309.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Table 4. Characteristics of different tools for creation of multimodal interfaces.",
                    "bbox": {
                        "x0": 144.4824981689453,
                        "y0": 322.4000244140625,
                        "x1": 462.600341796875,
                        "y1": 332.2400207519531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "ICARE",
                    "bbox": {
                        "x0": 289.260009765625,
                        "y0": 381.5969543457031,
                        "x1": 298.1400146484375,
                        "y1": 408.5299987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "–",
                    "bbox": {
                        "x0": 289.260009765625,
                        "y0": 374.8356018066406,
                        "x1": 298.1400146484375,
                        "y1": 379.2756042480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "OI",
                    "bbox": {
                        "x0": 289.260009765625,
                        "y0": 363.04986572265625,
                        "x1": 298.1400146484375,
                        "y1": 372.5070495605469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "[10]",
                    "bbox": {
                        "x0": 289.260009765625,
                        "y0": 345.798583984375,
                        "x1": 298.1400146484375,
                        "y1": 360.7604675292969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "OpenInterface",
                    "bbox": {
                        "x0": 311.5799865722656,
                        "y0": 357.0881652832031,
                        "x1": 320.4599914550781,
                        "y1": 408.5299987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "[61]",
                    "bbox": {
                        "x0": 311.5799865722656,
                        "y0": 339.852783203125,
                        "x1": 320.4599914550781,
                        "y1": 354.8146667480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "IMBuilder/",
                    "bbox": {
                        "x0": 333.6600036621094,
                        "y0": 368.04608154296875,
                        "x1": 342.5400085449219,
                        "y1": 408.5299987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "MEngine",
                    "bbox": {
                        "x0": 343.9800109863281,
                        "y0": 375.07904052734375,
                        "x1": 352.8600158691406,
                        "y1": 408.5299987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "[11]",
                    "bbox": {
                        "x0": 343.9800109863281,
                        "y0": 357.82635498046875,
                        "x1": 352.8600158691406,
                        "y1": 372.784912109375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Flippo",
                    "bbox": {
                        "x0": 363.17999267578125,
                        "y0": 385.06903076171875,
                        "x1": 372.05999755859375,
                        "y1": 408.5299987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "et",
                    "bbox": {
                        "x0": 363.17999267578125,
                        "y0": 376.29559326171875,
                        "x1": 372.05999755859375,
                        "y1": 382.7602233886719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "al.",
                    "bbox": {
                        "x0": 363.17999267578125,
                        "y0": 365.29327392578125,
                        "x1": 372.05999755859375,
                        "y1": 374.013427734375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "[22]",
                    "bbox": {
                        "x0": 363.17999267578125,
                        "y0": 348.0749816894531,
                        "x1": 372.05999755859375,
                        "y1": 363.0367431640625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Krahnstoever",
                    "bbox": {
                        "x0": 385.260009765625,
                        "y0": 360.07183837890625,
                        "x1": 394.1400146484375,
                        "y1": 408.5299987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "[32]",
                    "bbox": {
                        "x0": 385.260009765625,
                        "y0": 342.841064453125,
                        "x1": 394.1400146484375,
                        "y1": 357.8029479980469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Quickset",
                    "bbox": {
                        "x0": 407.5799865722656,
                        "y0": 376.56201171875,
                        "x1": 416.4599914550781,
                        "y1": 408.5299987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "[17]",
                    "bbox": {
                        "x0": 407.5799865722656,
                        "y0": 359.3293762207031,
                        "x1": 416.4599914550781,
                        "y1": 374.2911682128906
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Phidgets",
                    "bbox": {
                        "x0": 429.6600036621094,
                        "y0": 377.5565490722656,
                        "x1": 438.5400085449219,
                        "y1": 408.5299987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "[25] Papier-Mâché",
                    "bbox": {
                        "x0": 429.6600036621094,
                        "y0": 358.0898132324219,
                        "x1": 461.3399963378906,
                        "y1": 408.5299987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "[30]",
                    "bbox": {
                        "x0": 452.4599914550781,
                        "y0": 340.832763671875,
                        "x1": 461.3399963378906,
                        "y1": 355.7946472167969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Architecture traits",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 413.6000061035156,
                        "x1": 198.17471313476562,
                        "y1": 422.4800109863281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Finite state machine x",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 424.6399841308594,
                        "x1": 343.62481689453125,
                        "y1": 433.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Components x x x",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 435.44000244140625,
                        "x1": 436.3247985839844,
                        "y1": 444.32000732421875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Software agents x x",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 446.239990234375,
                        "x1": 413.96978759765625,
                        "y1": 455.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Fusion by frames x",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 457.2799987792969,
                        "x1": 391.6499938964844,
                        "y1": 466.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Symbolic-statistical fusion x",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 468.0799865722656,
                        "x1": 413.96978759765625,
                        "y1": 476.9599914550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Reusability easiness",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 479.1199951171875,
                        "x1": 205.66943359375,
                        "y1": 488.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "No programming kit x x",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 489.91998291015625,
                        "x1": 413.96978759765625,
                        "y1": 498.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Low-level programming (e.g. via API) x x x",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 500.7200012207031,
                        "x1": 459.12481689453125,
                        "y1": 509.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Higher-level Programming",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 511.7600402832031,
                        "x1": 230.16384887695312,
                        "y1": 520.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Visual Programming tool x x x",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 522.5599975585938,
                        "x1": 343.62481689453125,
                        "y1": 531.43994140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Characteristics",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 533.6000366210938,
                        "x1": 186.4176025390625,
                        "y1": 542.47998046875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Extensibility x x x x",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 544.4000244140625,
                        "x1": 413.96978759765625,
                        "y1": 553.2799682617188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Pluggability x",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 555.2000122070312,
                        "x1": 436.3247985839844,
                        "y1": 564.0799560546875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Reusable components x x x",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 566.2400512695312,
                        "x1": 413.96978759765625,
                        "y1": 575.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Open Source x x x",
                    "bbox": {
                        "x0": 132.9600067138672,
                        "y0": 577.0400390625,
                        "x1": 459.12481689453125,
                        "y1": 585.9199829101562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Table 4 summarizes the different characteristics of the systems described above:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 599.8399658203125,
                        "x1": 470.7092590332031,
                        "y1": 609.6799926757812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "extensible systems (i.e. toolkits) have the potential ability to add other input",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 611.3599853515625,
                        "x1": 470.7190856933594,
                        "y1": 621.2000122070312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modalities in a practical way. Pluggability refers to the ability of a toolkit to insert",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 622.8800048828125,
                        "x1": 470.7691650390625,
                        "y1": 632.7200317382812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "itself into an architecture without having to rewrite everything. The other",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 634.4000244140625,
                        "x1": 470.69952392578125,
                        "y1": 644.2400512695312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "characteristics are self-explanatory.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 645.9199829101562,
                        "x1": 266.8655090332031,
                        "y1": 655.760009765625
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 18,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "18 Bruno Dumas1, Denis Lalanne1, Sharon Oviatt2",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 121.99996948242188,
                        "x1": 333.7164001464844,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "5 Multimodal interfaces in Switzerland",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.17999267578125,
                        "x1": 331.09210205078125,
                        "y1": 161.17999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "5.1 Multimodal Interfaces in IM2",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 198.79998779296875,
                        "x1": 272.4090576171875,
                        "y1": 208.63999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The Swiss National Center of Competence in Research (NCCR) on Interactive",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 221.5999755859375,
                        "x1": 470.73358154296875,
                        "y1": 231.4399871826172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Multimodal Information Management (IM2) is one of the 20 Swiss National Centers",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 233.1199951171875,
                        "x1": 470.7642517089844,
                        "y1": 242.9600067138672
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "of Competence in Research (NCCR). IM2 aims at developing natural multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 244.6400146484375,
                        "x1": 470.76519775390625,
                        "y1": 254.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interfaces for human-computer interaction and to foster collaboration, focusing on",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 256.15997314453125,
                        "x1": 470.7144470214844,
                        "y1": 265.9999694824219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "new multimodal technologies to support human interaction, in the context of smart",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 267.67999267578125,
                        "x1": 470.7191162109375,
                        "y1": 277.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "meeting rooms and remote meeting assistants.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 279.20001220703125,
                        "x1": 309.3038635253906,
                        "y1": 289.0400085449219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The Individual Project on “Human Machine Interaction” is part of the NCCR IM2.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 295.52001953125,
                        "x1": 470.8501892089844,
                        "y1": 305.3600158691406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "While other activities in IM2 develop multimodal analysis and recognition",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 307.03997802734375,
                        "x1": 470.7614440917969,
                        "y1": 316.8799743652344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "technologies, the primary objective of IM2.HMI is to build cutting-edge technologies",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 318.55999755859375,
                        "x1": 470.805908203125,
                        "y1": 328.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "to develop interactive multimodal meeting browsers. The main goal of IM2.HMI is to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 330.0799865722656,
                        "x1": 470.7992248535156,
                        "y1": 339.91998291015625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "design, develop and evaluate, with human subjects, novel interactive multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 341.6000061035156,
                        "x1": 470.82318115234375,
                        "y1": 351.44000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "meeting browsers/assistants.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 353.1199951171875,
                        "x1": 238.8282012939453,
                        "y1": 362.9599914550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Fig. 5. Multimodal processing chain in IM2 meeting application.",
                    "bbox": {
                        "x0": 167.8430938720703,
                        "y0": 472.1600036621094,
                        "x1": 428.04718017578125,
                        "y1": 482.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "In order to support the development of so-called meeting browsers (4), and facilitate",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 495.1999816894531,
                        "x1": 470.75250244140625,
                        "y1": 505.03997802734375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "access to multimodal data and annotations (2), the JFerret framework has been",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 506.719970703125,
                        "x1": 470.66986083984375,
                        "y1": 516.5599975585938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "designed and implemented. Using the JFerret framework, and taking benefits of most",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 518.239990234375,
                        "x1": 470.71905517578125,
                        "y1": 528.0800170898438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "of the multimodal analysis, multimodal input recognizers and multimodal indexing",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 529.760009765625,
                        "x1": 470.7804870605469,
                        "y1": 539.6000366210938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and retrieval strategies made available in IM2, various meeting browsers have been",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 541.52001953125,
                        "x1": 470.6994323730469,
                        "y1": 551.3600463867188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "implemented [33]. Those meeting browsers take benefit of most of the annotations",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 553.0400390625,
                        "x1": 470.72637939453125,
                        "y1": 562.8800659179688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "made available by the other IM2 IPs: speech browsers (accelerated and overlapped),",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 564.5599975585938,
                        "x1": 470.7909851074219,
                        "y1": 574.4000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "document-centric meeting browsers (JFriDoc, FaericWorld) [60], Dialog-centric",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 576.0799560546875,
                        "x1": 470.8070373535156,
                        "y1": 585.9199829101562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "browsers (TQB) [58], multimodal enabled browsers (Archivus, HephaisTK),",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 587.5999755859375,
                        "x1": 470.7646484375,
                        "y1": 597.4400024414062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multilingual (M3C) and recently personalized browsers (WotanEye) [34]. Most of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 599.1199951171875,
                        "x1": 470.8136901855469,
                        "y1": 608.9600219726562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "these meeting browsers are in fact complete and transversal systems that access the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 610.6400146484375,
                        "x1": 470.6894226074219,
                        "y1": 620.4800415039062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal meeting data, analyse them, process high level indexes and provide",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 622.1599731445312,
                        "x1": 470.8159484863281,
                        "y1": 632.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interactive user interfaces so that the user can browse the meeting corpora through",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 633.9199829101562,
                        "x1": 470.6600646972656,
                        "y1": 643.760009765625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal queries. In the last couple of years, IM2.HMI has gently shifted towards",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 645.4400024414062,
                        "x1": 470.78155517578125,
                        "y1": 655.280029296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "online, a.k.a real-time, meeting assistance leveraging on past works. This includes",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 656.9599609375,
                        "x1": 470.80108642578125,
                        "y1": 666.7999877929688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "new research on personalized meeting browsing, mobile and remote access to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 668.47998046875,
                        "x1": 470.70184326171875,
                        "y1": 678.3200073242188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "meetings [38], and meeting assistance before, during and after meetings.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 680.0,
                        "x1": 414.9170837402344,
                        "y1": 689.8400268554688
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [
                {
                    "type": "figure",
                    "bbox": {
                        "x0": 172.55999755859375,
                        "y0": 363.1400146484375,
                        "x1": 423.3599853515625,
                        "y1": 470.4200134277344
                    },
                    "vlm_description": "The image is a flowchart illustrating the process of managing multimedia meeting content. Here’s a detailed description of each component:\n\n1. **Recording**: \n   - Depicted on the left side, with icons of a microphone and a video camera, indicating audio and video recording capabilities.\n\n2. **Multimedia Meeting DB**:\n   - In the center, there is a database labeled \"Multimedia meeting DB.\" Arrows indicate data going into and coming out of this database.\n\n3. **Analysis**:\n   - To the top right, there is a section labeled with types of analyses: \"Speech analysis,\" \"Video/image analysis,\" and \"Document analysis.\" An arrow loops back to the database, suggesting ongoing or iterative analysis processes.\n\n4. **Meeting Browsing**:\n   - Below the database is a box labeled \"Meeting browsing,\" with an arrow pointing downwards, leading to \"Users.\"\n\n- **Users**:\n   - At the bottom, there’s a section specifying \"Users,\" indicating the end-users who access the processed and analyzed meeting content.\n\nThe diagram shows the workflow from recording meetings to storing the data in a database, analyzing it, and finally making it accessible for users to browse.",
                    "vlm_structured_data": null,
                    "associated_text_indices": null
                }
            ],
            "image_path": null
        },
        {
            "page_number": 19,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "Multimodal Interfaces: A Survey of Principles, Models and Frameworks 19",
                    "bbox": {
                        "x0": 180.66659545898438,
                        "y0": 121.99996948242188,
                        "x1": 470.8323669433594,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "IM2.HMI has tackled multimodality both at the content and at the interaction levels.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 160.6400146484375,
                        "x1": 470.83935546875,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "While projects handling multimodality at the content level try to use the best of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 172.15997314453125,
                        "x1": 470.6600341796875,
                        "y1": 181.99998474121094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal data indexing in order to create useful and usable meeting browsers,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 183.91998291015625,
                        "x1": 470.65997314453125,
                        "y1": 193.75999450683594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "research projects handling multimodality at the interaction level study and build novel",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 195.44000244140625,
                        "x1": 470.6502990722656,
                        "y1": 205.28001403808594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal interaction paradigms, benefiting from various input modes.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 206.96002197265625,
                        "x1": 413.971923828125,
                        "y1": 216.80003356933594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Archivus, developed in the framework of IM2, is a good example of a research",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 230.0,
                        "x1": 470.6501770019531,
                        "y1": 239.8400115966797
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "project handling multimodality both at the content and interaction levels. Archivus is",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 241.52001953125,
                        "x1": 470.6894836425781,
                        "y1": 251.3600311279297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "a multimodal (pen, voice, mouse and keyboard) language-enabled dialogue-based",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 253.03997802734375,
                        "x1": 470.8028259277344,
                        "y1": 262.8799743652344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interface for browsing and retrieving multimodal meeting data [1]. It allows users to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 264.55999755859375,
                        "x1": 470.7586364746094,
                        "y1": 274.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "access a multimedia database of recorded and annotated meetings, containing the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 276.08001708984375,
                        "x1": 470.6895446777344,
                        "y1": 285.9200134277344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "original video and audio streams, electronic copies of all documents used or referred",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 287.8399658203125,
                        "x1": 470.6654968261719,
                        "y1": 297.6799621582031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "to as well as handwritten notes made by participants during the meeting, and a text",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 299.3599853515625,
                        "x1": 470.7485656738281,
                        "y1": 309.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "transcript of the meeting itself [37, 42]. Multimodal man-machine interaction in this",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 310.8800048828125,
                        "x1": 470.77777099609375,
                        "y1": 320.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "context has been carefully studied. Large-scale Wizard of Oz experiments with the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 322.4000244140625,
                        "x1": 470.7503967285156,
                        "y1": 332.2400207519531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "system (involving 91 users) were carried out and it resulted in 180 hours of video data",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 333.91998291015625,
                        "x1": 470.640380859375,
                        "y1": 343.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and 70MB of text log files. The data was analyzed along several different lines",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 345.44000244140625,
                        "x1": 470.79290771484375,
                        "y1": 355.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "including the modalities most often used, contexts of use, relationships between",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 356.9599914550781,
                        "x1": 470.6697998046875,
                        "y1": 366.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modalities, usage change over time, training impact, etc. [36]. To summarize the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 368.47998046875,
                        "x1": 470.7749938964844,
                        "y1": 378.3199768066406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "major findings: exposure and training can have a strong impact on the way people use",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 380.0,
                        "x1": 470.7239990234375,
                        "y1": 389.8399963378906
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodality, and speech is a preferred modality both at the content and interaction",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 391.760009765625,
                        "x1": 470.669921875,
                        "y1": 401.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "levels, i.e. as a cue for querying the multimodal database and as an interaction",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 403.2799987792969,
                        "x1": 470.70928955078125,
                        "y1": 413.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "channel.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 414.79998779296875,
                        "x1": 158.5846710205078,
                        "y1": 424.6399841308594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "HephaisTK, developed both in the framework of the NCCR IM2 and of the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 437.8399963378906,
                        "x1": 470.76275634765625,
                        "y1": 447.67999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "MeModules project presented in chapter 5, handles multimodality at the interaction",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 449.3599853515625,
                        "x1": 470.6304016113281,
                        "y1": 459.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "level and aims at providing a tool allowing developers to easily prototype multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 460.8800048828125,
                        "x1": 470.7288513183594,
                        "y1": 470.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interfaces [20]. The HephaisTK toolkit has been designed to plug itself in a client",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 472.3999938964844,
                        "x1": 470.7490539550781,
                        "y1": 482.239990234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "application that wishes to receive notifications of multimodal events received from a",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 484.1600036621094,
                        "x1": 470.6895751953125,
                        "y1": 494.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "set of modality recognizers. It is based on a software agents architecture, in which",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 495.67999267578125,
                        "x1": 470.6697692871094,
                        "y1": 505.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "agents, collaborating through a blackboard, are dispatched to manage individual",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 507.199951171875,
                        "x1": 470.7190856933594,
                        "y1": 517.0399780273438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modality recognizers, handle fusion and dialog management. HephaisTK can be",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 518.719970703125,
                        "x1": 470.73883056640625,
                        "y1": 528.5599975585938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "configured with the SMUIML language (Synchronized Multimodal User Interfaces",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 530.239990234375,
                        "x1": 470.7647705078125,
                        "y1": 540.0800170898438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Markup Language) [19], allowing a clear description of the human-machine",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 541.760009765625,
                        "x1": 470.80865478515625,
                        "y1": 551.6000366210938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal dialog and control over the way multiple input modalities have to be",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 553.280029296875,
                        "x1": 470.70928955078125,
                        "y1": 563.1200561523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "fused. More details about this tool can be found in chapter 5 of this book.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 564.7999877929688,
                        "x1": 418.173583984375,
                        "y1": 574.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "5.2 Multimodal Interfaces in the MMI program",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 598.1599731445312,
                        "x1": 332.8965148925781,
                        "y1": 608.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The IM-HOST project, described in detail in chapter 4 of this book, is representative",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 620.9599609375,
                        "x1": 470.6663818359375,
                        "y1": 630.7999877929688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "of one class of multimodal applications, although it focuses on a single modality:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 632.47998046875,
                        "x1": 470.66009521484375,
                        "y1": 642.3200073242188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "speech, which has been historically the leading modality in multimodal interaction.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 644.0,
                        "x1": 470.80084228515625,
                        "y1": 653.8400268554688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The IM-HOST project targets voice-enabled man-machine interaction in noisy",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 655.52001953125,
                        "x1": 470.76708984375,
                        "y1": 665.3600463867188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "environments. However, still, current performances of voice applications are",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 667.280029296875,
                        "x1": 470.71905517578125,
                        "y1": 677.1200561523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "reasonably good in quiet environments but the surrounding noise in many practical",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 678.7999877929688,
                        "x1": 470.8474426269531,
                        "y1": 688.6400146484375
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 20,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "20 Bruno Dumas1, Denis Lalanne1, Sharon Oviatt2",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 121.99996948242188,
                        "x1": 333.7164001464844,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "situations drastically deteriorates the quality of the speech signal and, as a",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 149.1199951171875,
                        "x1": 470.72900390625,
                        "y1": 158.9600067138672
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "consequence, significantly decreases the recognition rate. The major scenario",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 160.6400146484375,
                        "x1": 470.6698913574219,
                        "y1": 170.4800262451172
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "considered in this project is a person using voice command in an outdoor",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 172.15997314453125,
                        "x1": 470.7388000488281,
                        "y1": 181.99998474121094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "environment: a racing boat. For this reason, the project explores new interaction",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 183.91998291015625,
                        "x1": 470.690185546875,
                        "y1": 193.75999450683594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "paradigms enabling voice recognition in a hostile environment.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 195.44000244140625,
                        "x1": 377.5935363769531,
                        "y1": 205.28001403808594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "The MeModules project, fully detailed in chapter 5 of this book, has the objective of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 218.47998046875,
                        "x1": 470.68963623046875,
                        "y1": 228.3199920654297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "developing, experimenting and evaluating the concept of tangible shortcuts to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 230.0,
                        "x1": 470.7468566894531,
                        "y1": 239.8400115966797
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimedia digital information. Moreover, it investigates the opportunity of a more",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 241.52001953125,
                        "x1": 470.709228515625,
                        "y1": 251.3600311279297
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "complex, multi-sensorial combination of physical objects with multimedia",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 253.03997802734375,
                        "x1": 470.73419189453125,
                        "y1": 262.8799743652344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "information by associating tangible interaction with multiple other interaction",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 264.55999755859375,
                        "x1": 470.787841796875,
                        "y1": 274.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modalities such as voice, gesture, etc. One of the expected research outcomes of the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 276.08001708984375,
                        "x1": 470.6304626464844,
                        "y1": 285.9200134277344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "project is to assess which modalities are best combined with tangible interaction",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 287.8399658203125,
                        "x1": 470.65997314453125,
                        "y1": 297.6799621582031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "depending on the context and application.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 299.3599853515625,
                        "x1": 292.11346435546875,
                        "y1": 309.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "6 Future directions and conclusions",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 336.8599853515625,
                        "x1": 313.05780029296875,
                        "y1": 348.8599853515625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Although many issues have been addressed well in the multimodal interaction",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 364.6399841308594,
                        "x1": 470.7370910644531,
                        "y1": 374.47998046875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "research and systems literature, such as fusion of heterogeneous data types,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 376.1600036621094,
                        "x1": 470.8171081542969,
                        "y1": 386.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "architectures for real-time processing, dialog management, map-based multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 387.67999267578125,
                        "x1": 470.81036376953125,
                        "y1": 397.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interaction, and so forth, nonetheless the field is still young and needs further research",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 399.44000244140625,
                        "x1": 470.7309875488281,
                        "y1": 409.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "to build reliable multimodal systems and usable applications. Machine learning",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 410.9599914550781,
                        "x1": 470.7445068359375,
                        "y1": 420.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "methods have begun to be applied to a number of different aspects of multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 422.47998046875,
                        "x1": 470.6698913574219,
                        "y1": 432.3199768066406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interfaces, including individual modality recognition, early or late modality fusion,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 434.0,
                        "x1": 470.7376403808594,
                        "y1": 443.8399963378906
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "user-machine dialog management, and identification of users’ multimodal integration",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 445.5199890136719,
                        "x1": 470.6897277832031,
                        "y1": 455.3599853515625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "patterns. But future work clearly is needed to work toward the design of usable",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 457.0400085449219,
                        "x1": 470.67974853515625,
                        "y1": 466.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "adaptive multimodal interfaces. Multimodal dialog processing also will gain in the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 468.55999755859375,
                        "x1": 470.7304992675781,
                        "y1": 478.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "future from the recent and promising subfield of social signal processing, which can",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 480.0799865722656,
                        "x1": 470.68951416015625,
                        "y1": 489.91998291015625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "assist dialog modeling by providing a dialog manager with real-time information",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 491.6000061035156,
                        "x1": 470.7709655761719,
                        "y1": 501.44000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "about a given user’s state and her current social and collaborative context.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 503.3599853515625,
                        "x1": 420.9338684082031,
                        "y1": 513.2000122070312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Other important future directions for multimodal research include human/machine",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 526.4000244140625,
                        "x1": 470.6647033691406,
                        "y1": 536.2400512695312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interaction using new tangible interfaces such as digital paper and pen, and multi-",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 537.9199829101562,
                        "x1": 470.8221435546875,
                        "y1": 547.760009765625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "touch tables, surfaces and screens. Further modeling of multimodal interaction still is",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 549.4400024414062,
                        "x1": 470.7504577636719,
                        "y1": 559.280029296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "needed too, in areas such as multimodal educational exchanges, collaborative",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 560.9599609375,
                        "x1": 470.66986083984375,
                        "y1": 570.7999877929688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal interaction, multimodal interaction involving diverse and underserved",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 572.47998046875,
                        "x1": 470.6798095703125,
                        "y1": 582.3200073242188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "user groups, and mobile multimodal interaction with emerging cell phone",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 584.0,
                        "x1": 470.812744140625,
                        "y1": 593.8400268554688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "applications. Finally, further work is needed to improve tools for the creation of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 595.760009765625,
                        "x1": 470.66009521484375,
                        "y1": 605.6000366210938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal applications and interfaces so they can become more mainstream,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 607.280029296875,
                        "x1": 470.6697692871094,
                        "y1": 617.1200561523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "especially since multimodal interfaces are viewed as the most promising avenue for",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 618.7999877929688,
                        "x1": 470.70916748046875,
                        "y1": 628.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "achieving universal access in the near future.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 630.3200073242188,
                        "x1": 304.5835266113281,
                        "y1": 640.1600341796875
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 21,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "Multimodal Interfaces: A Survey of Principles, Models and Frameworks 21",
                    "bbox": {
                        "x0": 180.66659545898438,
                        "y0": 121.99996948242188,
                        "x1": 470.8323669433594,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "References",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 148.8800048828125,
                        "x1": 171.6029815673828,
                        "y1": 158.7200164794922
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "1. Ailomaa, M., Lisowska, A., Melichar, M., Armstrong, S., Rajmanm M.: Archivus: A",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 171.43997192382812,
                        "x1": 470.8077697753906,
                        "y1": 180.31997680664062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Multimodal System for Multimedia Meeting Browsing and Retrieval. In: Proceedings of the",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 181.75997924804688,
                        "x1": 470.8554382324219,
                        "y1": 190.63998413085938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "COLING/ACL 2006 Interactive Presentation Sessions. Sydney, Australia July 17th-21st",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 192.31997680664062,
                        "x1": 470.8589782714844,
                        "y1": 201.19998168945312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "(2006).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 202.63998413085938,
                        "x1": 162.60870361328125,
                        "y1": 211.51998901367188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "2. Allen, J.F., Perault, C.R.: Analyzing Intentions in Dialogues. Artiﬁcial Intelligence, 15(3),",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 212.95999145507812,
                        "x1": 470.9907531738281,
                        "y1": 221.83999633789062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "pp. 143--178 (1980).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 223.51998901367188,
                        "x1": 211.39535522460938,
                        "y1": 232.39999389648438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "3. André, E.: The generation of multimedia documents. In: Dale, R., Moisl, H., Somers, H.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 233.83999633789062,
                        "x1": 470.86016845703125,
                        "y1": 242.72000122070312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "(eds), A Handbook of Natural Language Processing: Techniques and Applications for the",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 244.16000366210938,
                        "x1": 470.9610900878906,
                        "y1": 253.04000854492188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Processing of Language as Text, pp. 305–-327. Marcel Dekker Inc. (2000).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 254.72000122070312,
                        "x1": 407.0765075683594,
                        "y1": 263.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "4. Araki, M., Tachibana, K.: Multimodal Dialog Description Language for Rapid System",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 265.0400085449219,
                        "x1": 470.88201904296875,
                        "y1": 273.9200134277344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Development. In: Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 275.3600158691406,
                        "x1": 470.9375305175781,
                        "y1": 284.2400207519531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "July 2006 (2006).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 285.6800231933594,
                        "x1": 200.13082885742188,
                        "y1": 294.5600280761719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "5. Baddeley, A.D.: Working Memory. Science, 255, pp. 556--559 (1992).",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 296.2400207519531,
                        "x1": 392.34600830078125,
                        "y1": 305.1200256347656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "6. Baddeley, A.D.: Working Memory. In: Bower, G.A. (ed.), Recent advances in learning and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 306.5599670410156,
                        "x1": 470.8998718261719,
                        "y1": 315.4399719238281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "motivation, vol. 8. New York: Academic Press (1974).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 316.8799743652344,
                        "x1": 333.58685302734375,
                        "y1": 325.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "7. Arens, Y., Hovy, E., Vossers, M.: On the knowledge underlying multimedia presentations.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 327.44000244140625,
                        "x1": 470.9441223144531,
                        "y1": 336.32000732421875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "In: Maybury, M.T. (ed.), Intelligent Multimedia Interfaces. AAAI Press, pp. 280--306",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 337.760009765625,
                        "x1": 470.83453369140625,
                        "y1": 346.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "(1993). Reprinted in Maybury and Wahlster, pp. 157--172 (1998).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 348.0799865722656,
                        "x1": 374.3621520996094,
                        "y1": 356.9599914550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "8. Benoit, C., Martin, J.-C., Pelachaud, C., Schomaker, L., Suhm, B.: Audio-visual and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 358.6399841308594,
                        "x1": 470.8467102050781,
                        "y1": 367.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal speech-based systems. In: Gibbon, D., Mertins, I., Moore, R. (Eds.), Handbook",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 368.9599914550781,
                        "x1": 470.8384094238281,
                        "y1": 377.8399963378906
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "of Multimodal and Spoken Dialogue Systems: Resources, Terminology and Product",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 379.2799987792969,
                        "x1": 470.8851013183594,
                        "y1": 388.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Evaluation, pp. 102--203, Kluwer (2000).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 389.8399963378906,
                        "x1": 286.35870361328125,
                        "y1": 398.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "9. Bolt, R.A.: Put-that-there: voice and gesture at the graphics interface. Computer Graphics,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 400.1600036621094,
                        "x1": 470.87432861328125,
                        "y1": 409.0400085449219
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "14(3), pp. 262--270 (1980).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 410.4800109863281,
                        "x1": 235.37339782714844,
                        "y1": 419.3600158691406
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "10. Bouchet, J., Nigay, L., Ganille, T.: ICARE Software Components for Rapidly Developing",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 420.79998779296875,
                        "x1": 470.8403625488281,
                        "y1": 429.67999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Multimodal Interfaces. In: Conference Proceedings of ICMI'2004, State College,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 431.3599853515625,
                        "x1": 470.9530334472656,
                        "y1": 440.239990234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Pennsylvania, USA, October 2004, ACM Press, pp. 251--258 (2004).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 441.67999267578125,
                        "x1": 386.39434814453125,
                        "y1": 450.55999755859375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "11. Bourguet, M. L.: A Toolkit for Creating and Testing Multimodal Interface Designs. In:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 452.0,
                        "x1": 470.98870849609375,
                        "y1": 460.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "companion proceedings of UIST'02, Paris, Oct. 2002, pp. 29--30 (2002).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 462.55999755859375,
                        "x1": 397.7388916015625,
                        "y1": 471.44000244140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "12. Brooke, N.M., Petajan, E.D.: Seeing speech: Investigations into the synthesis and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 472.8800048828125,
                        "x1": 470.87725830078125,
                        "y1": 481.760009765625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "recognition of visible speech movements using automatic image processing and computer",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 483.1999816894531,
                        "x1": 470.9442138671875,
                        "y1": 492.0799865722656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "graphics. In: Proceedings of the International Conference on Speech Input and Output:",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 493.760009765625,
                        "x1": 470.9156494140625,
                        "y1": 502.6400146484375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Techniques and Applications (1986), 258, pp. 104--109 (1986).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 504.0799865722656,
                        "x1": 365.1217346191406,
                        "y1": 512.9599609375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "13. Bui T.H.: Multimodal Dialogue Management - State of the Art. CTIT Technical Report",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 514.4000244140625,
                        "x1": 470.8995361328125,
                        "y1": 523.2799682617188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "series No. 06-01, University of Twente (UT), Enschede, The Netherlands (2006).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 524.7200317382812,
                        "x1": 429.0855712890625,
                        "y1": 533.5999755859375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "14. Card, S., Moran, T.P., Newell, A.: The Psychology of Human-Computer Interaction.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 535.280029296875,
                        "x1": 470.8601989746094,
                        "y1": 544.1599731445312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Lawrence Erlbaum Associates, London (1983).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 545.6000366210938,
                        "x1": 306.8281555175781,
                        "y1": 554.47998046875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "15. Churcher, G., Atwell, E., Souter, C.: Dialogue management systems: a survey and overview.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 555.9199829101562,
                        "x1": 470.92645263671875,
                        "y1": 564.7999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "1997.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 566.4800415039062,
                        "x1": 156.61883544921875,
                        "y1": 575.3599853515625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "16. Cohen, P.: Dialogue Modeling. In: Cole, R., Mariani, J., Uszkoreit, H., Varile, G.B., Zaenen,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 576.7999877929688,
                        "x1": 470.9115295410156,
                        "y1": 585.679931640625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "A., Zampolli, A.(eds), Survey of the State of the Art in Human Language Technology, pp.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 587.1200561523438,
                        "x1": 470.859619140625,
                        "y1": 596.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "204-209, Cambridge University Press (1998).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 597.6799926757812,
                        "x1": 300.8945617675781,
                        "y1": 606.5599365234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "17. Cohen, P. R., Johnston, M., McGee, D., Oviatt, S., Pittman, J., Smith, I., Chen, L., Clow, J.:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 608.0000610351562,
                        "x1": 470.85455322265625,
                        "y1": 616.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "QuickSet: multimodal interaction for distributed applications. In: Proceedings of the Fifth",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 618.3200073242188,
                        "x1": 471.0330810546875,
                        "y1": 627.199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "ACM international Conference on Multimedia, Seattle, USA, pp. 31--40, (1997).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 628.8800048828125,
                        "x1": 428.10614013671875,
                        "y1": 637.7599487304688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "18. Coutaz, J., Nigay, L., Salber, D., Blandford, A., May, J. Young, R.: Four Easy Pieces for",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 639.2000122070312,
                        "x1": 470.8363037109375,
                        "y1": 648.0799560546875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Assessing the Usability of Multimodal Interaction: The CARE properties. In: Proceedings of",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 649.52001953125,
                        "x1": 470.97979736328125,
                        "y1": 658.3999633789062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "INTERACT'95, Lillehammer, Norway, June 1995, pp. 115--120, Chapman & Hall Publ.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 659.8400268554688,
                        "x1": 470.8944091796875,
                        "y1": 668.719970703125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "(1995).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 670.4000244140625,
                        "x1": 162.62171936035156,
                        "y1": 679.2799682617188
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 22,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "22 Bruno Dumas1, Denis Lalanne1, Sharon Oviatt2",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 121.99996948242188,
                        "x1": 333.7164001464844,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "19. Dumas, B., Lalanne, D., Ingold, R.: Prototyping Multimodal Interfaces with SMUIML",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 148.87997436523438,
                        "x1": 470.90625,
                        "y1": 157.75997924804688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Modeling Language. In: CHI 2008 Workshop on User Interface Description Languages for",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 159.19998168945312,
                        "x1": 470.9886169433594,
                        "y1": 168.07998657226562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Next Generation User Interfaces, CHI 2008, Firenze, Italy, pp. 63--66 (2008).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 169.75997924804688,
                        "x1": 416.3189697265625,
                        "y1": 178.63998413085938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "20. Dumas, B., Lalanne, D., Guinard, D., Ingold, R., Koenig, R.: Strengths and Weaknesses of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 180.07998657226562,
                        "x1": 470.88812255859375,
                        "y1": 188.95999145507812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Software Architectures for the Rapid Creation of Tangible and Multimodal Interfaces. In:",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 190.39999389648438,
                        "x1": 470.9974365234375,
                        "y1": 199.27999877929688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Proceedings of 2nd international conference on Tangible and Embedded Interaction (TEI",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 200.95999145507812,
                        "x1": 471.04193115234375,
                        "y1": 209.83999633789062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "2008), Bonn (Germany), February 19 - 21 2008 , pp. 47--54 (2008).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 211.27999877929688,
                        "x1": 380.8770751953125,
                        "y1": 220.16000366210938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "21. Duric, Z., Gray, W., Heishman, R., Li, F., Rosenfeld, A., Schoelles, M., Schunn, C.,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 221.60000610351562,
                        "x1": 470.8568115234375,
                        "y1": 230.48001098632812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Wechsler, H.: Integrating perceptual and cognitive modeling for adaptive and intelligent",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 232.16000366210938,
                        "x1": 470.8619079589844,
                        "y1": 241.04000854492188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "human-computer interaction. In: Proc. of the IEEE, 90(7), pp. 1272--1289 (2002).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 242.48001098632812,
                        "x1": 431.33428955078125,
                        "y1": 251.36001586914062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "22. Flippo, F., Krebs, A. Marsic I.: A Framework for Rapid Development of Multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 252.80001831054688,
                        "x1": 470.92633056640625,
                        "y1": 261.6800231933594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Interfaces. In: Proceedings of ICMI'03, Vancouver, BC, Nov. 5-7, pp. 109--116 (2003).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 263.3600158691406,
                        "x1": 451.73223876953125,
                        "y1": 272.2400207519531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "23. Foster, M.E. State of the art review: Multimodal fission. COMIC project Deliverable 6.1.",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 273.6800231933594,
                        "x1": 470.9112243652344,
                        "y1": 282.5600280761719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "September 2002 (2002).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 283.9999694824219,
                        "x1": 223.6273193359375,
                        "y1": 292.8799743652344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "24. Grant, K.W. Greenberg, S.: Speech intelligibility derived from asynchronous processing of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 294.3199768066406,
                        "x1": 470.94451904296875,
                        "y1": 303.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "auditory-visual information. In: Workshop on Audio-Visual Speech Processing (AVSP-",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 304.8799743652344,
                        "x1": 470.8369445800781,
                        "y1": 313.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "2001). Scheelsminde, Denmark, pp. 132--137 (2001).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 315.1999816894531,
                        "x1": 329.3548278808594,
                        "y1": 324.0799865722656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "25. Greenberg, S., Fitchett, C.: Phidgets: easy development of physical interfaces through",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 325.5199890136719,
                        "x1": 470.88848876953125,
                        "y1": 334.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "physical widgets. In: Proceedings of the 14th Annual ACM Symposium on User interface",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 336.0799865722656,
                        "x1": 470.8466796875,
                        "y1": 344.9599914550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Software and Technology (UIST '01), Orlando, Florida, November 11-14, 2001, ACM, New",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 346.3999938964844,
                        "x1": 470.79156494140625,
                        "y1": 355.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "York, NY, pp. 209--218 (2001).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 356.7200012207031,
                        "x1": 251.8572998046875,
                        "y1": 365.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "26. Jaimes, A., Sebe, N.: Multimodal human-computer interaction: A survey. In: Computer",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 367.2799987792969,
                        "x1": 470.8651123046875,
                        "y1": 376.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Vision and Image Understanding 108, 1-2 (Oct. 2007), Elsevier, pp.116--134 (2007).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 377.6000061035156,
                        "x1": 442.8576354980469,
                        "y1": 386.4800109863281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "27. Johnston, M., Cohen, P. R., McGee, D., Oviatt, S. L., Pittman, J. A., Smith, I.: Unification-",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 387.91998291015625,
                        "x1": 470.8369445800781,
                        "y1": 396.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "based multimodal integration. In: Proceedings of the Eighth Conference on European",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 398.239990234375,
                        "x1": 470.89990234375,
                        "y1": 407.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Chapter of the Association For Computational Linguistics (Madrid, Spain, July 07-12,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 408.79998779296875,
                        "x1": 470.8645324707031,
                        "y1": 417.67999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "1997), pp. 281--288 (1997).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 419.1199951171875,
                        "x1": 236.88279724121094,
                        "y1": 428.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "28. Katsurada, K., Nakamura, Y., Yamada, H., Nitta, T.: 2003. XISL: a language for describing",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 429.44000244140625,
                        "x1": 470.868408203125,
                        "y1": 438.32000732421875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal interaction scenarios. In: Proceedings of ICMI’03, Vancouver, Canada (2003).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 440.0,
                        "x1": 463.1298522949219,
                        "y1": 448.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "29. Kieras, D. Meyer, D.E.: An overview of the EPIC architecture for cognition and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 450.32000732421875,
                        "x1": 470.8320617675781,
                        "y1": 459.20001220703125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "performance with application to human-computer interaction. In: Human-Computer",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 460.6399841308594,
                        "x1": 470.85858154296875,
                        "y1": 469.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Interaction, 12, pp. 391--438 (1997).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 471.1999816894531,
                        "x1": 268.35870361328125,
                        "y1": 480.0799865722656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "30. Klemmer, S. R., Li, J., Lin, J., Landay, J. A.: Papier-Mâché: Toolkit Support for Tangible",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 481.5199890136719,
                        "x1": 470.9109802246094,
                        "y1": 490.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Input. In: Proceedings of CHI 2004, pp. 399--406 (2004).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 491.8399963378906,
                        "x1": 343.3645935058594,
                        "y1": 500.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "31. Koons, D., Sparrell, C., Thorisson, K.: Integrating simultaneous input from speech, gaze,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 502.3999938964844,
                        "x1": 470.9797668457031,
                        "y1": 511.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "and hand gestures. In: M. Maybury (Ed.), Intelligent Multimedia Interfaces. Cambridge,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 512.7200317382812,
                        "x1": 470.99755859375,
                        "y1": 521.5999755859375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "MA: MIT Press, pp. 257--276 (1993).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 523.0400390625,
                        "x1": 272.9055480957031,
                        "y1": 531.9199829101562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "32. Krahnstoever, N., Kettebekov, S., Yeasin, M. Sharma, R.: A real-time framework for natural",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 533.3600463867188,
                        "x1": 470.9037780761719,
                        "y1": 542.239990234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "multimodal interaction with large screen displays. In: ICMI’02, Pittsburgh, USA, Oct. 2002.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 543.9199829101562,
                        "x1": 469.0887145996094,
                        "y1": 552.7999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "33. Lalanne, D., Lisowska, A., Bruno, E., Flynn, M., Georgescul, M., Guillemot, M., Janvier,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 554.2400512695312,
                        "x1": 470.8731384277344,
                        "y1": 563.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "B., Marchand-Maillet, S., Melichar, M., Moenne-Loccoz, N., Popescu-Belis, A., Rajman,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 564.5599975585938,
                        "x1": 470.8589782714844,
                        "y1": 573.43994140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "M., Rigamonti, M., von Rotz, D., Wellner, P.: The IM2 Multimodal Meeting Browser",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 575.1200561523438,
                        "x1": 470.881591796875,
                        "y1": 584.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Family, Technical report, Fribourg, March 2005 (2005).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 585.4400024414062,
                        "x1": 338.3197021484375,
                        "y1": 594.3199462890625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "34. Lalanne, D., Rigamonti, M., Evequoz, F., Dumas, B., Ingold, R.: An ego-centric and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 595.760009765625,
                        "x1": 470.8492736816406,
                        "y1": 604.6399536132812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "tangible approach to meeting indexing and browsing, In: Popescu-Belis A., Bourlard H.,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 606.3200073242188,
                        "x1": 470.8767395019531,
                        "y1": 615.199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Renals S. (eds.), Machine Learning for Multimodal Interaction IV, Revised Selected Papers,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 616.6400146484375,
                        "x1": 471.0063781738281,
                        "y1": 625.5199584960938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "LNCS 4892, Springer-Verlag, Berlin/Heidelberg, pp. 84-95 (2008).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 626.9600219726562,
                        "x1": 379.5675354003906,
                        "y1": 635.8399658203125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "35. Lisowska, A.: Multimodal Interface Design for Multimedia Meeting Content Retrieval. PhD",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 637.280029296875,
                        "x1": 470.9465026855469,
                        "y1": 646.1599731445312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Thesis, University of Geneva, Switzerland, September 2007 (2007).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 647.8400268554688,
                        "x1": 381.0653076171875,
                        "y1": 656.719970703125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "36. Lisowska, A., Betrancourt, M., Armstrong, S., Rajman, M.: Minimizing Modality Bias",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 658.1600341796875,
                        "x1": 470.843017578125,
                        "y1": 667.0399780273438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "When Exploring Input Preference for Multimodal Systems in New Domains: the Archivus",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 668.4800415039062,
                        "x1": 470.9175720214844,
                        "y1": 677.3599853515625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Case Study. In: Proceedings of CHI’ 07, San José, California, pp. 1805-1810 (2007).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 679.0400390625,
                        "x1": 441.84600830078125,
                        "y1": 687.9199829101562
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 23,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "Multimodal Interfaces: A Survey of Principles, Models and Frameworks 23",
                    "bbox": {
                        "x0": 180.66659545898438,
                        "y0": 121.99996948242188,
                        "x1": 470.8323669433594,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "37. Lisowska, A.: Multimodal Interface Design for the Multimodal Meeting Domain:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 148.87997436523438,
                        "x1": 470.965576171875,
                        "y1": 157.75997924804688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Preliminary Indications from a Query Analysis Study. IM2.MDM Internal Report",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 159.19998168945312,
                        "x1": 470.8818664550781,
                        "y1": 168.07998657226562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "IM2.MDM-11, November 2003 (2003).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 169.75997924804688,
                        "x1": 279.85919189453125,
                        "y1": 178.63998413085938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "38. Matena L., Jaimes A., Popescu-Belis A.: Graphical representation of meetings on mobile",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 180.07998657226562,
                        "x1": 470.9006042480469,
                        "y1": 188.95999145507812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "devices. In: Proceedings of MobileHCI 2008 (10th International Conference on Human-",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 190.39999389648438,
                        "x1": 470.8369445800781,
                        "y1": 199.27999877929688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Computer Interaction with Mobile Devices and Services), Amsterdam, pp. 503--506 (2008).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 200.95999145507812,
                        "x1": 468.3143005371094,
                        "y1": 209.83999633789062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "39. Mayer, R.E., Moreno, R.: A split-attention effect in multimedia learning: evidence for dual",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 211.27999877929688,
                        "x1": 470.98468017578125,
                        "y1": 220.16000366210938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "processing systems in working memory. In: Journal of Educational Psychology, 1998. 90(2),",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 221.60000610351562,
                        "x1": 470.89996337890625,
                        "y1": 230.48001098632812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "pp. 312--320 (1998).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 232.16000366210938,
                        "x1": 211.3888702392578,
                        "y1": 241.04000854492188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "40. McKeown, K.: Text Generation: Using Discourse Strategies and Focus Constraints to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 242.48001098632812,
                        "x1": 470.95513916015625,
                        "y1": 251.36001586914062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Generate Natural Language Text. Cambridge University Press (1985).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 252.80001831054688,
                        "x1": 389.0369873046875,
                        "y1": 261.6800231933594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "41. McNeill, D.: Hand and Mind: What Gestures Reveal About Thought, Univ. of Chicago",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 263.3600158691406,
                        "x1": 470.8372497558594,
                        "y1": 272.2400207519531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Press, Chicago, IL (1992).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 273.6800231933594,
                        "x1": 231.34800720214844,
                        "y1": 282.5600280761719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "42. Melichar, M., Cenek, P.: From vocal to multimodal dialogue management. In: Proceedings",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 283.9999694824219,
                        "x1": 470.87469482421875,
                        "y1": 292.8799743652344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "of the Eighth International Conference on Multimodal Interfaces (ICMI’06), Banff, Canada,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 294.3199768066406,
                        "x1": 470.96722412109375,
                        "y1": 303.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "November 2-4 2006, pp. 59--67 (2006).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 304.8799743652344,
                        "x1": 279.37579345703125,
                        "y1": 313.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "43. Moore, J.D.: Participating in Explanatory Dialogues: Interpreting and Responding to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 315.1999816894531,
                        "x1": 470.9562072753906,
                        "y1": 324.0799865722656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Questions in Context. MIT Press, Cambridge, Massachusetts (1995).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 325.5199890136719,
                        "x1": 384.0931091308594,
                        "y1": 334.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "44. Mousavi, S.Y., Low, R., Sweller, J.: Reducing cognitive load by mixing auditory and visual",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 336.0799865722656,
                        "x1": 470.9486083984375,
                        "y1": 344.9599914550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "presentation modes. In: Journal of Educational Psychology, 1995, 87(2), pp. 319--334",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 346.3999938964844,
                        "x1": 470.83453369140625,
                        "y1": 355.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "(1995).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 356.7200012207031,
                        "x1": 162.60870361328125,
                        "y1": 365.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "45. Neal, J.G., Shapiro, S.C.: Intelligent multimedia interface technology. In: Sullivan, J., Tyler,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 367.2799987792969,
                        "x1": 470.8601989746094,
                        "y1": 376.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "S. (eds.), Intelligent User Interfaces, ACM Press, New York, pp. 11--43 (1991).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 377.6000061035156,
                        "x1": 423.5823974609375,
                        "y1": 386.4800109863281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "46. Nigay, L., Coutaz, J.A.: Design space for multimodal systems: concurrent processing and",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 387.91998291015625,
                        "x1": 470.873291015625,
                        "y1": 396.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "data fusion. In Proceedings of the INTERACT '93 and CHI '93 Conference on Human",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 398.239990234375,
                        "x1": 470.94427490234375,
                        "y1": 407.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Factors in Computing Systems (Amsterdam, The Netherlands, April 24 - 29, 1993). ACM,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 408.79998779296875,
                        "x1": 470.8548278808594,
                        "y1": 417.67999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "New York, NY, pp. 172--178 (1993).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 419.1199951171875,
                        "x1": 271.10089111328125,
                        "y1": 428.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "47. Norman, D.A.: The Design of Everyday Things. New York: Basic Book (1988).",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 429.44000244140625,
                        "x1": 425.3182067871094,
                        "y1": 438.32000732421875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "48. Novick, D. G., Ward, K.: Mutual Beliefs of Multiple Conversants: A computational model",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 440.0,
                        "x1": 470.95074462890625,
                        "y1": 448.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "of collaboration in Air Trafic Control. In: Proceedings of AAAI’93, pp. 196--201 (1993).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 450.32000732421875,
                        "x1": 457.8553466796875,
                        "y1": 459.20001220703125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "49. Oviatt, S.L.: Advances in Robust Multimodal Interface Design. In: IEEE Computer",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 460.6399841308594,
                        "x1": 470.8619384765625,
                        "y1": 469.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Graphics and Applications, vol. 23, september 2003 (2003).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 471.1999816894531,
                        "x1": 352.0746154785156,
                        "y1": 480.0799865722656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "50. Oviatt, S.L.: Multimodal interactive maps: Designing for human performance. In: Human-",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 481.5199890136719,
                        "x1": 470.8369445800781,
                        "y1": 490.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Computer Interaction, vol. 12, pp. 93--129 (1997).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 491.8399963378906,
                        "x1": 318.1178283691406,
                        "y1": 500.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "51. Oviatt, S.L.: Multimodal interfaces. In: J. Jacko, J., Sears, A. (eds), The Human-Computer",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 502.3999938964844,
                        "x1": 470.85858154296875,
                        "y1": 511.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Interaction Handbook: Fundamentals, Evolving Technologies and Emerging Applications,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 512.7200317382812,
                        "x1": 470.9885559082031,
                        "y1": 521.5999755859375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "2nd edition, CRC Press, 2008, chap. 14, pp. 286—304 (2008).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 522.1399536132812,
                        "x1": 357.27569580078125,
                        "y1": 531.9199829101562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "52. Oviatt, S.L.: Ten myths of multimodal interaction. In: Communications of the ACM, 42(11),",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 533.3600463867188,
                        "x1": 470.9353942871094,
                        "y1": 542.239990234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "New York: ACM Press, pp. 74--81 (1999).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 543.9199829101562,
                        "x1": 291.1363830566406,
                        "y1": 552.7999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "53. Oviatt, S.L.: Human-centered design meets cognitive load theory: designing interfaces that",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 554.2400512695312,
                        "x1": 470.8628234863281,
                        "y1": 563.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "help people think. In: Proceedings of the 14th Annual ACM international Conference on",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 564.5599975585938,
                        "x1": 470.9449462890625,
                        "y1": 573.43994140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Multimedia (Santa Barbara, CA, USA, October 23-27, 2006), ACM, New York, NY, pp.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 575.1200561523438,
                        "x1": 470.8645324707031,
                        "y1": 584.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "871--880 (2006).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 585.4400024414062,
                        "x1": 197.8791961669922,
                        "y1": 594.3199462890625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "54. Oviatt, S. L., Cohen, P. R., Wu, L., Vergo, J., Duncan, L., Suhm, B., Bers, J., Holzman, T.,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 595.760009765625,
                        "x1": 470.8387756347656,
                        "y1": 604.6399536132812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Winograd, T., Landay, J., Larson, J., Ferro, D.: Designing the user interface for multimodal",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 606.3200073242188,
                        "x1": 470.9075927734375,
                        "y1": 615.199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "speech and gesture applications: State-of-the-art systems and research directions. In: Human",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 616.6400146484375,
                        "x1": 470.83135986328125,
                        "y1": 625.5199584960938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Computer Interaction, 2000, vol. 15, no. 4, pp. 263--322 [Reprinted in Human-Computer",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 626.9600219726562,
                        "x1": 470.85858154296875,
                        "y1": 635.8399658203125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Interaction in the New Millennium (ed. J. Carroll), Addison-Wesley Press, Reading, MA,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 637.280029296875,
                        "x1": 470.8524475097656,
                        "y1": 646.1599731445312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "2001; chapter 19, pp. 421--456] (2000).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 647.8400268554688,
                        "x1": 279.35821533203125,
                        "y1": 656.719970703125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "55. Oviatt, S.L., Coulston, R., Tomko, S., Xiao, B., Lunsford, R., Wesson, M., Carmichael, L.:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 658.1600341796875,
                        "x1": 470.85833740234375,
                        "y1": 667.0399780273438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Toward a theory of organized multimodal integration patterns during human-computer",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 668.4800415039062,
                        "x1": 470.8600158691406,
                        "y1": 677.3599853515625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "interaction. In: Proceedings of ICMI 2003, ACM Press, pp. 44--51 (2003).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 679.0400390625,
                        "x1": 404.6112060546875,
                        "y1": 687.9199829101562
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 24,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "24 Bruno Dumas1, Denis Lalanne1, Sharon Oviatt2",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 121.99996948242188,
                        "x1": 333.7164001464844,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "56. Pan, H., Liang, Z.P., Anastasio, T.J., Huang, T.S.: Exploiting the dependencies in",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 148.87997436523438,
                        "x1": 470.89105224609375,
                        "y1": 157.75997924804688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "information fusion. In: CVPR, vol. 2, pp. 407--412 (1999).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 159.19998168945312,
                        "x1": 348.39190673828125,
                        "y1": 168.07998657226562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "57. Petajan, E.D.: Automatic Lipreading to Enhance Speech Recognition, PhD thesis,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 169.75997924804688,
                        "x1": 470.9755554199219,
                        "y1": 178.63998413085938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "University of Illinois at Urbana-Champaign (1984).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 180.07998657226562,
                        "x1": 322.3411865234375,
                        "y1": 188.95999145507812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "58. Popescu-Belis A., Georgescul M.: TQB: Accessing Multimedia Data Using a Transcript-",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 190.39999389648438,
                        "x1": 470.8369445800781,
                        "y1": 199.27999877929688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "based Query and Browsing Interface. In: Proceedings of LREC 2006 (5th International",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 200.95999145507812,
                        "x1": 470.91754150390625,
                        "y1": 209.83999633789062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Conference on Language Resources and Evaluation), Genoa, Italy, pp. 1560--1565 (2006).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 211.27999877929688,
                        "x1": 463.0408935546875,
                        "y1": 220.16000366210938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "59. Reeves, L. M., Lai, J., Larson, J. A., Oviatt, S., Balaji, T. S., Buisine, S. p., Collings, P.,",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 221.60000610351562,
                        "x1": 470.8707275390625,
                        "y1": 230.48001098632812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Cohen, P., Kraal, B., Martin, J.-C., McTear, M., Raman, T., Stanney, K. M., Su, H. Wang,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 232.16000366210938,
                        "x1": 470.864990234375,
                        "y1": 241.04000854492188
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Q.Y.: Guidelines for multimodal user interface design. In: Communications of the ACM",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 242.48001098632812,
                        "x1": 470.8625793457031,
                        "y1": 251.36001586914062
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "47(1), pp. 57--59 (2004).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 252.80001831054688,
                        "x1": 226.3778076171875,
                        "y1": 261.6800231933594
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "60. Rigamonti, M., Lalanne, D., Ingold, R.: FaericWorld: Browsing Multimedia Events Through",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 263.3600158691406,
                        "x1": 470.917724609375,
                        "y1": 272.2400207519531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Static Documents And Links. In: Interact 2007, the eleventh IFIP TC13 International",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 273.6800231933594,
                        "x1": 470.954833984375,
                        "y1": 282.5600280761719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Conference on Human-Computer Interaction, Rio de Janeiro, INTERACT (1) 2007, pp.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 283.9999694824219,
                        "x1": 470.8625793457031,
                        "y1": 292.8799743652344
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "102--115 (2007).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 294.3199768066406,
                        "x1": 197.8888702392578,
                        "y1": 303.1999816894531
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "61. Serrano, M., Nigay, L., Lawson, J.-Y.L., Ramsay, A., Murray-Smith, R., Denef. S.: The",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 304.8799743652344,
                        "x1": 470.8429870605469,
                        "y1": 313.7599792480469
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "OpenInterface framework: a tool for multimodal interaction. In: Adjunct Proceedings of",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 315.1999816894531,
                        "x1": 470.88885498046875,
                        "y1": 324.0799865722656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "CHI’2008 (April 5-10, Florence, Italy), ACM Press, pp. 3501--3506 (2008).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 325.5199890136719,
                        "x1": 410.6272888183594,
                        "y1": 334.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "62. Sharma, R., Pavlovic, V. I., Huang, T.S.: Toward multimodal human-computer interface. In:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 336.0799865722656,
                        "x1": 470.8648376464844,
                        "y1": 344.9599914550781
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Proceedings IEEE, 86(5) [Special issue on Multimedia Signal Processing], pp. 853--860",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 346.3999938964844,
                        "x1": 470.83453369140625,
                        "y1": 355.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "(1998).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 356.7200012207031,
                        "x1": 162.60870361328125,
                        "y1": 365.6000061035156
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "63. Sire, S., Chatty, C.: The Markup Way to Multimodal Toolkits, In: W3C Multimodal",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 367.2799987792969,
                        "x1": 470.9530029296875,
                        "y1": 376.1600036621094
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Interaction Workshop (2002).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 377.6000061035156,
                        "x1": 243.5911407470703,
                        "y1": 386.4800109863281
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "64. SSPNet: Social Signal Processing Network, http://www.sspnet.eu",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 387.91998291015625,
                        "x1": 372.7720642089844,
                        "y1": 396.79998779296875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "65. Stanciulescu, A., Limbourg, Q., Vanderdonckt, J., Michotte, B., Montero, F.: A",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 398.239990234375,
                        "x1": 470.8197937011719,
                        "y1": 407.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "transformational approach for multimodal web user interfaces based on UsiXML. In:",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 408.79998779296875,
                        "x1": 470.9530029296875,
                        "y1": 417.67999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Proceedings of ICMI 2005, Torento, Italy, October 04-06, pp. 259--266 (2005).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 419.1199951171875,
                        "x1": 422.86895751953125,
                        "y1": 428.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "66. Sweller, J., Chandler, P., Tierney, P., Cooper, M.: Cognitive Load as a Factor in the",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 429.44000244140625,
                        "x1": 470.8999328613281,
                        "y1": 438.32000732421875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Structuring of Technical Material. In: Journal of Experimental Psychology: General, 119,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 440.0,
                        "x1": 470.86572265625,
                        "y1": 448.8800048828125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "pp. 176--192 (1990).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 450.32000732421875,
                        "x1": 211.39535522460938,
                        "y1": 459.20001220703125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "67. Tindall-Ford, S., Chandler, P., Sweller, J.: When two sensory modes are better than one. In:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 460.6399841308594,
                        "x1": 470.8648376464844,
                        "y1": 469.5199890136719
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Journal of Experimental Psychology: Applied, 3(3), pp. 257--287 (1997).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 471.1999816894531,
                        "x1": 400.3572998046875,
                        "y1": 480.0799865722656
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "68. Traum D., Larsson, S.: The Information State Approach to Dialogue Management. In: Van",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 481.5199890136719,
                        "x1": 470.9263610839844,
                        "y1": 490.3999938964844
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Kuppevelt, J.C.J, Smith, R.W. (eds.): Current and New Directions in Discourse and",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 491.8399963378906,
                        "x1": 470.87451171875,
                        "y1": 500.7200012207031
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Dialogue, pp. 325--353 (2003).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 502.3999938964844,
                        "x1": 248.8851318359375,
                        "y1": 511.2799987792969
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "69. Turk, M., Robertson, G.: Perceptual user interfaces (Introduction). In: Communications of",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 512.7200317382812,
                        "x1": 470.9619140625,
                        "y1": 521.5999755859375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "the ACM, 43(3), pp. 32--70 (2000).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 523.0400390625,
                        "x1": 264.6460876464844,
                        "y1": 531.9199829101562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "70. Vo, M.T., Wood, C.: Building an application framework for speech and pen input",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 533.3600463867188,
                        "x1": 470.9220886230469,
                        "y1": 542.239990234375
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "integration in multimodal learning interfaces. In: Proceedings of the International",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 543.9199829101562,
                        "x1": 471.0419616699219,
                        "y1": 552.7999267578125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Conference on Acoustics Speech and Signal Processing (IEEE-ICASSP) Vol.6, IEEE Press,",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 554.2400512695312,
                        "x1": 470.8849792480469,
                        "y1": 563.1199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "pp. 3545—3548 (1996).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 564.5599975585938,
                        "x1": 223.2978973388672,
                        "y1": 573.43994140625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "71. W3C Multimodal Interaction Framework, http://www.w3.org/TR/mmi-framework",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 575.1200561523438,
                        "x1": 433.4029846191406,
                        "y1": 584.0
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "72. Wickens, C.: Multiple resources and performance prediction. In: Theoretical Issues in",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 585.4400024414062,
                        "x1": 470.8418273925781,
                        "y1": 594.3199462890625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Ergonomic Science, 3(2), pp. 159--177 (2002).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 595.760009765625,
                        "x1": 305.6023864746094,
                        "y1": 604.6399536132812
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "73. Wickens, C., Sandry, D., Vidulich, M.: Compatibility and resource competition between",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 606.3200073242188,
                        "x1": 470.8587646484375,
                        "y1": 615.199951171875
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "modalities of input, central processing, and output. In: Human Factors, 25(2), pp. 227--248",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 616.6400146484375,
                        "x1": 470.83453369140625,
                        "y1": 625.5199584960938
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "(1983).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 626.9600219726562,
                        "x1": 162.60870361328125,
                        "y1": 635.8399658203125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "74. Wu, L., Oviatt, S., Cohen, P.: From members to teams to committee - a robust approach to",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 637.280029296875,
                        "x1": 470.8460998535156,
                        "y1": 646.1599731445312
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "gestural and multimodal recognition. In: IEEE Transactions on Neural Networks, 13(4), pp.",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 647.8400268554688,
                        "x1": 470.9222717285156,
                        "y1": 656.719970703125
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "972--982 (2002).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 658.1600341796875,
                        "x1": 197.89535522460938,
                        "y1": 667.0399780273438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "75. Wu, L., Oviatt, S., Cohen, P.: Multimodal integration – A statistical view. In: IEEE",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 668.4800415039062,
                        "x1": 470.83599853515625,
                        "y1": 677.3599853515625
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Transactions on Multimedia, 1(4), pp. 334--341 (1999).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 679.0400390625,
                        "x1": 336.8768615722656,
                        "y1": 687.9199829101562
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [],
            "image_path": null
        },
        {
            "page_number": 25,
            "dimensions": [
                595.0,
                842.0
            ],
            "text_blocks": [
                {
                    "text": "Multimodal Interfaces: A Survey of Principles, Models and Frameworks 25",
                    "bbox": {
                        "x0": 180.66659545898438,
                        "y0": 121.99996948242188,
                        "x1": 470.8323669433594,
                        "y1": 130.87997436523438
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "76. Zhai, S., Morimoto, C., Ihde, S.: Manual and gaze input cascaded (MAGIC) pointing. In:",
                    "bbox": {
                        "x0": 125.04010009765625,
                        "y0": 148.87997436523438,
                        "x1": 470.90155029296875,
                        "y1": 157.75997924804688
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "Proceedings of the Conference on Human Factors in Computing Systems (CHI'99), New",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 159.19998168945312,
                        "x1": 470.890869140625,
                        "y1": 168.07998657226562
                    },
                    "layoutlm_embedding": null
                },
                {
                    "text": "York, ACM Press, pp. 246--253 (1999).",
                    "bbox": {
                        "x0": 136.39019775390625,
                        "y0": 169.75997924804688,
                        "x1": 280.64434814453125,
                        "y1": 178.63998413085938
                    },
                    "layoutlm_embedding": null
                }
            ],
            "annotations": [],
            "visual_elements": [],
            "image_path": null
        }
    ]
}