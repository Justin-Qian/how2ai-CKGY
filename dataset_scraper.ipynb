{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 200 annotations so far...\n",
      "Fetched 400 annotations so far...\n",
      "Fetched 600 annotations so far...\n",
      "Fetched 800 annotations so far...\n",
      "Fetched 1000 annotations so far...\n",
      "Fetched 1200 annotations so far...\n",
      "Fetched 1400 annotations so far...\n",
      "Fetched 1600 annotations so far...\n",
      "Fetched 1800 annotations so far...\n",
      "Fetched 2000 annotations so far...\n",
      "Fetched 2200 annotations so far...\n",
      "Fetched 2400 annotations so far...\n",
      "Fetched 2600 annotations so far...\n",
      "Fetched 2800 annotations so far...\n",
      "Fetched 3000 annotations so far...\n",
      "Fetched 3200 annotations so far...\n",
      "Fetched 3400 annotations so far...\n",
      "Fetched 3600 annotations so far...\n",
      "Fetched 3800 annotations so far...\n",
      "Fetched 4000 annotations so far...\n",
      "Fetched 4200 annotations so far...\n",
      "Fetched 4400 annotations so far...\n",
      "Fetched 4600 annotations so far...\n",
      "Fetched 4800 annotations so far...\n",
      "Fetched 5000 annotations so far...\n",
      "\n",
      "Successfully fetched 5000 annotations.\n",
      "Annotations successfully organized and saved to annotations_database.json.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script retrieves and structures annotation data from Hypothes.is, an open-source annotation platform widely utilized in educational contexts, where students collaboratively annotate and comment on digital texts such as articles, academic papers, and online resources. Hypothes.is provides a valuable dataset for analyzing student interactions, highlighting meaningful excerpts, and capturing individual insights directly associated with specific text fragments (Hypothes.is, n.d.). Leveraging students' annotations enhances the construction of personalized knowledge graphs, as these annotations inherently represent authentic user engagement and reflection, making them ideal for building nuanced, context-rich educational applications.\n",
    "\n",
    "Reference:\n",
    "Hypothes.is. (n.d.). Hypothes.is API documentation. Retrieved March 25, 2025, from https://h.readthedocs.io/en/latest/api/\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "HYPOTHESIS_API_URL = \"https://api.hypothes.is/api/search\"\n",
    "\n",
    "def fetch_annotations_paginated(total_annotations=5000, per_page=200, sleep_between_calls=1):\n",
    "    annotations = []\n",
    "    offset = 0\n",
    "\n",
    "    while len(annotations) < total_annotations:\n",
    "        params = {\n",
    "            \"limit\": per_page,\n",
    "            \"offset\": offset,\n",
    "            # optionally add user or group filtering here\n",
    "        }\n",
    "\n",
    "        response = requests.get(HYPOTHESIS_API_URL, params=params)\n",
    "        response.raise_for_status()\n",
    "        batch = response.json().get('rows', [])\n",
    "\n",
    "        # If no more annotations, break loop\n",
    "        if not batch:\n",
    "            break\n",
    "\n",
    "        annotations.extend(batch)\n",
    "        offset += per_page\n",
    "\n",
    "        print(f\"Fetched {len(annotations)} annotations so far...\")\n",
    "\n",
    "        # Respect API limits (avoid rate limiting)\n",
    "        time.sleep(sleep_between_calls)\n",
    "\n",
    "    # Limit annotations to desired total (exactly 5,000)\n",
    "    return annotations[:total_annotations]\n",
    "\n",
    "# Structure annotations by user and document (only with titles, no tags)\n",
    "def organize_annotations(annotations):\n",
    "    data = defaultdict(lambda: defaultdict(lambda: {\"title\": \"\", \"annotations\": []}))\n",
    "\n",
    "    for ann in annotations:\n",
    "        doc_title = ann.get('document', {}).get('title', [])\n",
    "        if not doc_title or not doc_title[0].strip():\n",
    "            continue  # Skip documents without titles\n",
    "\n",
    "        doc_title = doc_title[0].strip()\n",
    "        user = ann.get('user', 'unknown_user').split(':')[1].split('@')[0]\n",
    "        doc_uri = ann.get('uri', 'unknown_document')\n",
    "\n",
    "        annotation = {\n",
    "            \"id\": ann.get('id'),\n",
    "            \"highlighted_text\": \"\",\n",
    "            \"comment\": ann.get('text', ''),\n",
    "            \"created\": ann.get('created'),\n",
    "            \"position\": {},\n",
    "            \"context\": {}\n",
    "        }\n",
    "\n",
    "        target = ann.get('target', [])\n",
    "        if target:\n",
    "            selectors = target[0].get('selector', [])\n",
    "            for selector in selectors:\n",
    "                if selector['type'] == 'TextQuoteSelector':\n",
    "                    annotation[\"highlighted_text\"] = selector.get('exact', '')\n",
    "                    annotation[\"context\"] = {\n",
    "                        \"preceding_text\": selector.get('prefix', ''),\n",
    "                        \"following_text\": selector.get('suffix', '')\n",
    "                    }\n",
    "                elif selector['type'] == 'TextPositionSelector':\n",
    "                    annotation[\"position\"] = {\n",
    "                        \"start_char\": selector.get('start'),\n",
    "                        \"end_char\": selector.get('end')\n",
    "                    }\n",
    "\n",
    "        doc_entry = data[user][doc_uri]\n",
    "        doc_entry[\"title\"] = doc_title\n",
    "        doc_entry[\"annotations\"].append(annotation)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    TOTAL_ANNOTATIONS = 5000\n",
    "    annotations = fetch_annotations_paginated(total_annotations=TOTAL_ANNOTATIONS)\n",
    "\n",
    "    print(f\"\\nSuccessfully fetched {len(annotations)} annotations.\")\n",
    "\n",
    "    structured_data = organize_annotations(annotations)\n",
    "\n",
    "    # Save structured data to a JSON file\n",
    "    with open(\"annotations_database.json\", \"w\", encoding='utf-8') as f:\n",
    "        json.dump(structured_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"Annotations successfully organized and saved to annotations_database.json.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
